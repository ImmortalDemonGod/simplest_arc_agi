{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Neural Circuit Extraction and Modular Composition Framework","text":"<p>Welcome to the documentation for the Neural Circuit Extraction and Modular Composition Framework, a system designed to advance our understanding of how neural networks learn, represent, and compose algorithms.</p>"},{"location":"#project-overview","title":"Project Overview","text":"<p>This project aims to build an automated, scalable system to:</p> <ol> <li>Generate diverse algorithmic task data</li> <li>Train optimized transformer models concurrently</li> <li>Extract and catalog interpretable neural circuits</li> <li>Enable modular composition of these circuits </li> </ol> <p>By systematically extracting, cataloging, and composing the underlying circuits in trained neural networks, we can:</p> <ul> <li>Gain deeper insights into learning dynamics (grokking, double descent, etc.)</li> <li>Build complex reasoning systems from verifiable, learned components</li> <li>Create a testbed for interpretability research</li> <li>Explore the limits of algorithmic complexity in neural networks</li> <li>Bridge the gap between neural computation and symbolic reasoning</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with this framework:</p> <pre><code># Clone the repository\ngit clone https://github.com/yourusername/simplest_arc_agi.git\ncd simplest_arc_agi\n\n# Install dependencies\npip install -r requirements.txt\n\n# Run a simple training experiment\npython main.py --task add_mod_11 --modulus 11 --max_epochs 5000\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Overview: Detailed project goals and motivation</li> <li>Components: Core system modules</li> <li>Implementation Roadmap: Development phases</li> <li>Future Directions: Research paths and extensions</li> <li>ARC Evaluation Protocol: Evaluation method aligned with ARC benchmark</li> <li>API Reference: Technical API documentation</li> <li>Tutorials: Step-by-step guides</li> </ul>"},{"location":"arc_evaluation/","title":"ARC Evaluation Protocol","text":"<p>This document outlines our approach for evaluating the Neural Circuit Extraction and Modular Composition Framework in alignment with the principles of the Abstraction and Reasoning Corpus (ARC) and Fran\u00e7ois Chollet's insights on general intelligence from \"On the Measure of Intelligence.\"</p>"},{"location":"arc_evaluation/#principles-of-arc-and-intelligence-measurement","title":"Principles of ARC and Intelligence Measurement","text":"<p>ARC evaluates systems based on their ability to solve novel, abstract reasoning tasks from just a few examples. Following Chollet's paper, true intelligence should be measured by:</p> <ol> <li>Skill-Acquisition Efficiency: Intelligence is the efficiency with which a system can turn experience (training data) into skill, not just the final skill level achieved.</li> <li>Core Knowledge: Human-like systems should rely on similar prior knowledge (objectness, basic physics, number sense, geometry, etc.) rather than extensive domain-specific training.</li> <li>Few-Shot Generalization: Systems should learn from very few examples (3-5 input/output pairs).</li> <li>Developer-Aware Evaluation: The evaluation tasks must be novel to both the system and its developers.</li> </ol>"},{"location":"arc_evaluation/#dedicated-evaluation-dataset","title":"Dedicated Evaluation Dataset","text":"<p>We've created a specialized evaluation framework:</p>"},{"location":"arc_evaluation/#dataset-creation","title":"Dataset Creation","text":"<ul> <li>Private Test Set: 100-200+ ARC-like tasks created specifically for evaluation</li> <li>Novel Compositions: Tasks focus on novel combinations of Core Knowledge primitives</li> <li>Strict Isolation: Tasks must not overlap with those used for training models or developing the circuit extraction/composition mechanisms</li> <li>Secrecy: The dataset remains strictly private until the moment of evaluation</li> </ul>"},{"location":"arc_evaluation/#task-format","title":"Task Format","text":"<p>Tasks follow the ARC format, with each task consisting of: - Multiple demonstration pairs (input/output grid examples) - One or more test inputs requiring correct predictions</p>"},{"location":"arc_evaluation/#standardized-solver-interface","title":"Standardized Solver Interface","text":"<p>Our evaluation uses a standardized interface:</p> <pre><code>def solve_arc_task(\n    example_pairs: List[Tuple[Grid, Grid]],  # Demonstration pairs\n    test_inputs: List[Grid]                  # Test inputs for evaluation\n) -&gt; List[Optional[Grid]]:                   # Predictions or None for failures\n</code></pre> <p>The system receives all demonstration pairs and test inputs for a task simultaneously, with no intermediate feedback.</p>"},{"location":"arc_evaluation/#evaluation-protocol","title":"Evaluation Protocol","text":"<p>Our protocol mirrors ARC's approach:</p> <ol> <li>For each task in the private evaluation set:</li> <li>Call <code>solve_arc_task</code> with the demonstration pairs and test inputs</li> <li>The solver processes the examples and makes predictions</li> <li> <p>No feedback is provided on test input predictions</p> </li> <li> <p>A task is considered solved only if the function returns the exact correct output grid for all test inputs.</p> </li> </ol>"},{"location":"arc_evaluation/#primary-evaluation-metrics","title":"Primary Evaluation Metrics","text":"<p>We track several key metrics:</p>"},{"location":"arc_evaluation/#primary-metric","title":"Primary Metric","text":"<ul> <li>Accuracy: Percentage of tasks solved correctly in the private evaluation set</li> </ul>"},{"location":"arc_evaluation/#secondary-metrics","title":"Secondary Metrics","text":"<ul> <li>Few-Shot Learning Curve: Performance as a function of example count (1, 2, 3...)</li> <li>Trial Efficiency: Average number of hypotheses generated/tested before finding the correct one</li> <li>Resource Consumption: LLM token usage, circuit calls, and wall-clock time per task</li> <li>Solution Complexity: Complexity of the generated circuit compositions</li> </ul>"},{"location":"arc_evaluation/#addressing-the-priors-problem","title":"Addressing the \"Priors\" Problem","text":"<p>To ensure fair evaluation aligned with Core Knowledge assumptions:</p>"},{"location":"arc_evaluation/#circuit-library-constraints","title":"Circuit Library Constraints","text":"<ul> <li>Core Knowledge Tagging: All circuits are tagged with their alignment to core cognitive capacities</li> <li>Strict Circuit Access: During evaluation, the system can only access circuits tagged as Core Knowledge primitives</li> <li>Prior Penalties: Non-Core or Compound circuits may incur penalties in hypothesis selection</li> </ul>"},{"location":"arc_evaluation/#llm-constraints","title":"LLM Constraints","text":"<ul> <li>Structured Prompting: LLMs are explicitly instructed to rely only on Core Knowledge primitives</li> <li>External Knowledge Prohibition: Instructions forbid leveraging external knowledge beyond examples</li> <li>Knowledge Auditing: LLM interactions are logged and audited for suspicious domain knowledge</li> </ul>"},{"location":"arc_evaluation/#rule-inference-mechanism","title":"Rule Inference Mechanism","text":"<p>Our framework implements a specific approach to inferring rules from few examples:</p> <ol> <li>Feature Extraction: For each example pair, we run analyzer circuits to extract features</li> <li>Differential Analysis: We identify consistent changes between input and output grids</li> <li>Hypothesis Generation: The LLM suggests potential transformations based on the analysis</li> <li>Circuit Query: The system queries the database for relevant primitive circuits</li> <li>Candidate Generation: The LLM generates candidate compositions to implement the hypothesized rule</li> <li>Verification: Candidates are tested against example pairs</li> <li>Selection: The simplest viable hypothesis is selected and applied to test inputs</li> </ol>"},{"location":"arc_evaluation/#developer-aware-generalization","title":"Developer-Aware Generalization","text":"<p>To maintain integrity of the evaluation:</p> <ul> <li>Strict Task Isolation: Tasks are generated after system freeze (training complete, circuits extracted)</li> <li>LLM Blinding: No task identifiers or metadata that could link to online ARC discussions</li> <li>Interaction Auditing: All LLM prompts and responses are logged and checked for suspicious knowledge</li> <li>Training Data Cutoffs: We prefer LLMs with documented training data cutoffs</li> <li>Human Benchmarking: Human participants solve the same tasks to establish fair comparison baselines</li> </ul>"},{"location":"arc_evaluation/#implementation-phases","title":"Implementation Phases","text":"<p>Our evaluation protocol will be implemented in these phases:</p> <ol> <li>Basic Task Validation: Initial testing with simple ARC-style tasks (currently implemented)</li> <li>Few-Shot Learning Optimization: Fine-tuning the LLM-circuit composition interface (in progress)</li> <li>Full Protocol Implementation: Complete system with all constraints and metrics (planned)</li> <li>Human Comparative Studies: Side-by-side evaluation with human participants (future)</li> </ol>"},{"location":"arc_evaluation/#alignment-with-chollets-framework","title":"Alignment with Chollet's Framework","text":"<p>Our approach aligns with Chollet's formal definition of intelligence: - <code>Span(ARC)</code> represents the space of problems constructed from Core Knowledge - <code>Spec(ARC)</code> is measured by our ARC-aligned evaluation set - <code>C(S, .)</code> is approximated by our metrics on hypothesis complexity - <code>Scope</code> is measured by the breadth of tasks our system can solve - <code>Generality</code> is assessed through the few-shot learning curve </p>"},{"location":"future_directions/","title":"Future Directions","text":"<p>This document outlines the long-term research and development roadmap for the Neural Circuit Extraction and Modular Composition Framework, highlighting areas where we see significant potential for innovation and impact.</p>"},{"location":"future_directions/#research-frontiers","title":"Research Frontiers","text":""},{"location":"future_directions/#advanced-circuit-extraction-techniques","title":"Advanced Circuit Extraction Techniques","text":"<ol> <li>Causal Intervention Methods</li> <li>Develop tools for automated counterfactual analysis</li> <li>Implement systematic activation patching at scale</li> <li> <p>Create metrics for quantifying circuit isolation accuracy</p> </li> <li> <p>Dynamic Circuit Discovery</p> </li> <li>Design algorithms for identifying circuits that activate conditionally</li> <li>Build tools for mapping context-dependent circuit behavior</li> <li> <p>Develop methods for tracking circuit evolution during training</p> </li> <li> <p>Multi-Modal Circuit Analysis</p> </li> <li>Extend extraction techniques to vision-language models</li> <li>Develop specialized approaches for audio, video, and multi-modal reasoning</li> <li>Research cross-modal transfer of circuit functionality</li> </ol>"},{"location":"future_directions/#compositional-ai-architectures","title":"Compositional AI Architectures","text":"<ol> <li>Learned Composition Rules</li> <li>Train meta-models that predict effective circuit compositions</li> <li>Develop composition optimization through reinforcement learning</li> <li> <p>Research automated discovery of composition patterns</p> </li> <li> <p>Self-Modifying Circuits</p> </li> <li>Design architectures where circuits can dynamically reconfigure</li> <li>Build frameworks for runtime circuit adaptation</li> <li> <p>Investigate emergence of higher-order composition</p> </li> <li> <p>Hierarchical Composition</p> </li> <li>Develop techniques for building complex functional hierarchies</li> <li>Research abstraction formation across circuit layers</li> <li>Create tools for navigating multi-level circuit compositions</li> </ol>"},{"location":"future_directions/#interpretability-advances","title":"Interpretability Advances","text":"<ol> <li>Natural Language Circuit Descriptions</li> <li>Create systems that generate human-readable circuit explanations</li> <li>Develop bidirectional translation between code and natural language descriptions</li> <li> <p>Research evaluation metrics for explanation quality</p> </li> <li> <p>Visualization Innovations</p> </li> <li>Build interactive 3D visualizations of circuit interactions</li> <li>Develop visual grammars for circuit function representation</li> <li> <p>Create dashboards for real-time circuit monitoring</p> </li> <li> <p>Conceptual Alignment</p> </li> <li>Research mapping between neural circuits and human conceptual structures</li> <li>Develop methods to align circuit functionality with human mental models</li> <li>Create frameworks for comparative circuit linguistics</li> </ol>"},{"location":"future_directions/#arc-specific-innovations","title":"ARC-Specific Innovations","text":"<ol> <li>Core Knowledge Primitives</li> <li>Systematically map circuit libraries to core cognitive primitives</li> <li>Develop domain-general reasoning circuits</li> <li> <p>Research minimal sufficient circuit sets for general reasoning</p> </li> <li> <p>Few-Shot Learning Mechanisms</p> </li> <li>Develop circuits specialized for rapid adaptation</li> <li>Research meta-learning at the circuit level</li> <li> <p>Build compositional structures that facilitate one/few-shot generalization</p> </li> <li> <p>Abstraction Hierarchies</p> </li> <li>Create multi-level abstraction capabilities through circuit composition</li> <li>Research emergence of symbolic reasoning from subsymbolic circuits</li> <li>Develop metrics for abstraction power</li> </ol>"},{"location":"future_directions/#technical-development","title":"Technical Development","text":""},{"location":"future_directions/#infrastructure-scaling","title":"Infrastructure Scaling","text":"<ol> <li>Distributed Circuit Database</li> <li>Build federated circuit repositories across research institutions</li> <li>Develop standards for circuit interchange</li> <li> <p>Create cloud-native circuit storage and retrieval systems</p> </li> <li> <p>High-Performance Inference</p> </li> <li>Optimize circuit execution for specialized hardware</li> <li>Develop just-in-time circuit compilation</li> <li> <p>Create adaptive batching for efficient circuit execution</p> </li> <li> <p>Training Infrastructure</p> </li> <li>Scale concurrent training to thousands of experiments</li> <li>Build automated circuit discovery pipelines</li> <li>Develop self-improving training systems</li> </ol>"},{"location":"future_directions/#tooling-and-interfaces","title":"Tooling and Interfaces","text":"<ol> <li>Developer Experience</li> <li>Create intuitive interfaces for circuit manipulation</li> <li>Build IDE integrations for circuit development</li> <li> <p>Develop debugging tools for circuit composition</p> </li> <li> <p>Circuit Marketplace</p> </li> <li>Design architecture for sharing and reusing circuits</li> <li>Develop standardized interfaces for plug-and-play composition</li> <li> <p>Create attribution and licensing frameworks for circuits</p> </li> <li> <p>Production Integration</p> </li> <li>Develop deployment pipelines for production applications</li> <li>Build monitoring systems for deployed circuits</li> <li>Create failover and redundancy mechanisms</li> </ol>"},{"location":"future_directions/#quality-and-safety","title":"Quality and Safety","text":"<ol> <li>Circuit Verification</li> <li>Develop formal verification tools for circuit compositions</li> <li>Build automated test generators for circuits</li> <li> <p>Create safety checking for composed circuits</p> </li> <li> <p>Alignment Properties</p> </li> <li>Research approaches to verifiable alignment at the circuit level</li> <li>Develop techniques for constraining circuit function</li> <li> <p>Build tools for detecting emergent capabilities in compositions</p> </li> <li> <p>Robustness Guarantees</p> </li> <li>Create stress-testing frameworks for circuits</li> <li>Develop adversarial testing for robustness</li> <li>Build tools for measuring circuit generalization boundaries</li> </ol>"},{"location":"future_directions/#applications-and-impact","title":"Applications and Impact","text":""},{"location":"future_directions/#scientific-applications","title":"Scientific Applications","text":"<ol> <li>Cognitive Science Integration</li> <li>Develop collaborations with cognitive science researchers</li> <li>Create tools for comparing human and artificial neural circuits</li> <li> <p>Build joint models of cognition based on circuit analysis</p> </li> <li> <p>Neuroscience-Inspired Methods</p> </li> <li>Research parallels between brain regions and neural circuits</li> <li>Develop biologically-inspired circuit structures</li> <li> <p>Build tools for comparative analysis of biological and artificial circuits</p> </li> <li> <p>Scientific Discovery</p> </li> <li>Apply circuit analysis to scientific models</li> <li>Develop specialized circuits for scientific data processing</li> <li>Create tools for hypothesis generation through circuit composition</li> </ol>"},{"location":"future_directions/#industry-applications","title":"Industry Applications","text":"<ol> <li>Modular AI Services</li> <li>Develop plug-and-play circuits for specific business functions</li> <li>Create composition platforms for non-technical users</li> <li> <p>Build circuit-based AI customization tools</p> </li> <li> <p>Explainable AI Systems</p> </li> <li>Develop audit trails for circuit-based decisions</li> <li>Create human-centered explanation interfaces</li> <li> <p>Build tools for detecting and addressing bias in circuits</p> </li> <li> <p>Efficient Deployment</p> </li> <li>Create optimization tools for circuit-based systems</li> <li>Develop specialized hardware for circuit execution</li> <li>Build frameworks for edge deployment of circuits</li> </ol>"},{"location":"future_directions/#social-impact","title":"Social Impact","text":"<ol> <li>Educational Applications</li> <li>Develop circuit-based tutoring systems</li> <li>Create tools for visualizing knowledge structures</li> <li> <p>Build adaptive learning systems using circuit composition</p> </li> <li> <p>Accessibility Innovations</p> </li> <li>Develop specialized circuits for accessibility challenges</li> <li>Create customizable interfaces based on circuit composition</li> <li> <p>Build tools for personalized assistive technologies</p> </li> <li> <p>Global Challenges</p> </li> <li>Apply circuit-based approaches to climate modeling</li> <li>Develop specialized systems for healthcare applications</li> <li>Create tools for sustainable development planning</li> </ol>"},{"location":"future_directions/#community-and-ecosystem","title":"Community and Ecosystem","text":""},{"location":"future_directions/#open-source-development","title":"Open Source Development","text":"<ol> <li>Community Framework</li> <li>Establish governance models for the open source project</li> <li>Create contributor guidelines and mentorship programs</li> <li> <p>Develop sustainability plans for long-term maintenance</p> </li> <li> <p>Educational Resources</p> </li> <li>Create comprehensive documentation and tutorials</li> <li>Develop university curriculum materials</li> <li> <p>Build interactive learning platforms</p> </li> <li> <p>Research Collaboration</p> </li> <li>Establish benchmark suites for circuit extraction and composition</li> <li>Create standardized evaluation metrics</li> <li>Develop shared research infrastructure</li> </ol>"},{"location":"future_directions/#ethics-and-governance","title":"Ethics and Governance","text":"<ol> <li>Responsible Innovation</li> <li>Develop ethical guidelines for circuit development</li> <li>Create impact assessment frameworks</li> <li> <p>Build tools for auditing circuit behavior</p> </li> <li> <p>Inclusive Development</p> </li> <li>Ensure diverse perspectives in system design</li> <li>Create multilingual and multicultural interfaces</li> <li> <p>Develop accessibility standards for tools</p> </li> <li> <p>Governance Structures</p> </li> <li>Establish advisory boards for ethical oversight</li> <li>Create transparent reporting mechanisms</li> <li>Develop community standards for acceptable use</li> </ol>"},{"location":"future_directions/#implementation-timeline","title":"Implementation Timeline","text":""},{"location":"future_directions/#near-term-1-2-years","title":"Near-Term (1-2 Years)","text":"<ul> <li>Complete core infrastructure for circuit extraction and composition</li> <li>Develop initial library of well-documented circuits</li> <li>Establish open source community and contribution pipeline</li> <li>Create basic tools for interpretability and visualization</li> <li>Achieve initial results on ARC through circuit composition</li> </ul>"},{"location":"future_directions/#mid-term-3-5-years","title":"Mid-Term (3-5 Years)","text":"<ul> <li>Scale circuit database to thousands of documented circuits</li> <li>Develop advanced composition frameworks with formal verification</li> <li>Create production-ready deployment pipelines</li> <li>Establish industry partnerships for specialized applications</li> <li>Achieve significant advances in few-shot learning capabilities</li> </ul>"},{"location":"future_directions/#long-term-5-years","title":"Long-Term (5+ Years)","text":"<ul> <li>Build self-improving systems of circuits</li> <li>Develop general reasoning capabilities through composition</li> <li>Create seamless integration with scientific discovery processes</li> <li>Establish standardized circuit marketplace</li> <li>Achieve human-competitive performance on complex reasoning tasks</li> </ul>"},{"location":"future_directions/#conclusion","title":"Conclusion","text":"<p>The Neural Circuit Extraction and Modular Composition Framework represents a significant shift in how we understand, build, and deploy artificial intelligence systems. By focusing on interpretability, modularity, and composition, we aim to create AI systems that are more transparent, reliable, and aligned with human values.</p> <p>Our long-term vision is to establish a new paradigm for AI development that combines the power of large-scale neural networks with the transparency and reliability of traditional software engineering. Through collaborative research and open source development, we believe this approach can address many of the current challenges in AI safety, interpretability, and generalization. </p>"},{"location":"overview/","title":"Project Overview","text":""},{"location":"overview/#vision-and-goals","title":"Vision and Goals","text":"<p>This project aims to build an automated, scalable system designed to advance our understanding of how neural networks learn, represent, and compose algorithms. The system integrates automatic data generation for diverse algorithmic tasks, concurrent training of highly optimized transformer models, advanced circuit extraction techniques, and a novel modular composition framework leveraging a cataloged library of neural circuits. </p> <p>The ultimate goal is to explore the potential for bootstrapping complex, abstract reasoning capabilities from simpler, verifiable learned components, potentially bridging the gap between emergent neural computation and structured algorithmic problem-solving.</p>"},{"location":"overview/#core-goals","title":"Core Goals","text":"<ol> <li> <p>Automatically Generate Diverse Algorithmic Task Data    Create structured datasets for a wide spectrum of algorithmic tasks, ranging from simple binary operations (e.g., <code>a \u25e6 b = c</code> for grokking studies) to more complex problems involving sequences, grids, or compositions of functions, leveraging primitives like those found in <code>arc_types</code>.</p> </li> <li> <p>Train Optimized Transformer Models Concurrently    Efficiently execute numerous training experiments across multiple tasks and model configurations simultaneously, leveraging state-of-the-art hardware (GPUs/TPUs) and distributed frameworks (e.g., Ray, Kubernetes, SLURM) to study learning dynamics and generate models for circuit analysis.</p> </li> <li> <p>Employ Highly Optimized and Adaptable Architectures    Utilize cutting-edge transformer optimizations (e.g., FlashAttention) and explore architectural modifications (e.g., advanced attention mechanisms) alongside techniques like model pruning and Low-Rank Adaptation (LoRA) to enhance efficiency, isolate core computational circuits, facilitate rapid task specialization, and create models amenable to modular analysis.</p> </li> <li> <p>Extract and Catalog Interpretable Neural Circuits    Apply advanced circuit extraction methods (e.g., cross-layer transcoding via dictionary learning, attribution graph construction) to identify, interpret, and systematically catalog the neural circuits responsible for specific algorithmic capabilities within trained models, storing them in a structured database.</p> </li> <li> <p>Enable Modular Composition of Circuits    Treat the cataloged circuits as functional building blocks with defined interfaces. Develop methods to compose these modules\u2014analogous to software engineering\u2014to represent and potentially execute arbitrarily complex algorithms. This includes exploring code-like representations for composed circuits and leveraging Large Language Models (LLMs) for composition assistance, aiming to overcome the complexity limitations of individual fixed-capacity models.</p> </li> </ol>"},{"location":"overview/#motivation","title":"Motivation","text":"<p>Understanding how neural networks perform algorithmic reasoning is crucial for building more reliable, interpretable, and capable AI systems. Phenomena like \"grokking\" (delayed generalization on simple algorithmic tasks) highlight gaps in our understanding of optimization dynamics and generalization in overparameterized models. </p> <p>By systematically extracting, cataloging, and composing the underlying circuits, we aim to:</p> <ul> <li>Gain deeper insights into learning dynamics, including grokking, double descent, and the emergence of algorithmic structures.</li> <li>Develop a framework for building complex reasoning systems from verifiable, learned components, drawing parallels with modular software engineering.</li> <li>Create a unique testbed for interpretability research, circuit analysis techniques, and modular AI design principles.</li> <li>Explore the limits of algorithmic complexity learnable by fixed-capacity models versus composed systems built from simpler, reusable circuits.</li> <li>Bridge the gap between sub-symbolic neural computation and symbolic algorithmic reasoning by representing circuits in a more structured, potentially code-like format.</li> </ul>"},{"location":"overview/#key-innovations","title":"Key Innovations","text":"<p>The key innovation in this system is the explicit extraction, cataloging, and structured composition of learned, emergent algorithmic primitives into verifiable programs. </p> <p>Traditional programming uses explicitly defined, human-coded functions. Standard deep learning uses (mostly) monolithic, end-to-end trained models where intermediate steps are emergent but not explicitly extracted, cataloged, or composed in a structured, verifiable way. Our system bridges this gap by:</p> <ol> <li>Learning neural implementations of algorithmic primitives</li> <li>Extracting and cataloging these as manipulable components  </li> <li>Composing them into novel configurations to solve new problems</li> <li>Providing verifiable reasoning traces for the composed systems </li> </ol>"},{"location":"roadmap/","title":"Implementation Roadmap","text":"<p>This roadmap outlines our phased approach to developing the Neural Circuit Extraction and Modular Composition Framework.</p>"},{"location":"roadmap/#phase-1-foundation-baseline-months-1-3","title":"Phase 1: Foundation &amp; Baseline (Months 1-3)","text":"<p>In this initial phase, we establish the core infrastructure and validate the basic approach:</p>"},{"location":"roadmap/#data-generator-v1","title":"Data Generator v1","text":"<ul> <li>Implement core <code>arc_types</code> functions for basic operations</li> <li>Develop generator for binary operation datasets (modular arithmetic)</li> <li>Create basic validation and testing procedures</li> </ul>"},{"location":"roadmap/#transformer-prototype-v1","title":"Transformer Prototype v1","text":"<ul> <li>Build small baseline transformer (2-layer, 128-width)</li> <li>Incorporate FlashAttention for performance optimization</li> <li>Validate on simple tasks like <code>add_mod_97</code></li> </ul>"},{"location":"roadmap/#training-framework-v1","title":"Training Framework v1","text":"<ul> <li>Set up basic infrastructure using Ray + W&amp;B for experiment tracking</li> <li>Implement tools for launching, monitoring, and logging single training jobs</li> <li>Tune hyperparameters for efficient generalization (grokking) on baseline tasks</li> </ul> <p>Milestones: - \u2705 Successfully train models that exhibit grokking on simple algorithmic tasks - \u2705 Basic training infrastructure operational - \u2705 Demonstrable generalization on held-out test data</p>"},{"location":"roadmap/#phase-2-parallelization-efficiency-optimization-months-4-6","title":"Phase 2: Parallelization, Efficiency &amp; Optimization (Months 4-6)","text":"<p>In this phase, we focus on scaling our infrastructure and improving model efficiency:</p>"},{"location":"roadmap/#concurrent-training","title":"Concurrent Training","text":"<ul> <li>Scale the framework to manage multiple concurrent training jobs</li> <li>Implement resource management across different tasks and hyperparameter settings</li> <li>Develop tools for comparing results across experiments</li> </ul>"},{"location":"roadmap/#efficiency-techniques","title":"Efficiency Techniques","text":"<ul> <li>Integrate and systematically evaluate model pruning</li> <li>Implement LoRA adapters for efficient fine-tuning</li> <li>Analyze impact on generalization speed, final accuracy, parameter count, and inference latency</li> </ul>"},{"location":"roadmap/#hpo-integration","title":"HPO Integration","text":"<ul> <li>Integrate automated hyperparameter optimization tools (Optuna, Ray Tune)</li> <li>Develop search spaces and optimization metrics</li> <li>Validate HPO effectiveness across different tasks</li> </ul> <p>Milestones: - \u2705 Demonstrate concurrent training of 10+ experiments - \u2705 Achieve 30%+ parameter reduction with minimal accuracy loss through pruning - \u2705 Show successful task-specific adaptation using LoRA</p>"},{"location":"roadmap/#phase-3-extraction-cataloging-visualization-months-7-9","title":"Phase 3: Extraction, Cataloging &amp; Visualization (Months 7-9)","text":"<p>This phase focuses on extracting and understanding the circuits within our trained models:</p>"},{"location":"roadmap/#circuit-extraction-v1","title":"Circuit Extraction v1","text":"<ul> <li>Implement CLT/dictionary learning pipeline</li> <li>Develop attribution graph generation tools</li> <li>Extract and analyze circuits from baseline models (and pruned/LoRA variants)</li> </ul>"},{"location":"roadmap/#database-v1","title":"Database v1","text":"<ul> <li>Design and implement the database schema with <code>interface_definition</code></li> <li>Create a functional system for storing task, model, training, and circuit data</li> <li>Develop APIs for querying and retrieving circuits</li> </ul>"},{"location":"roadmap/#visualization-v1","title":"Visualization v1","text":"<ul> <li>Develop tools for visualizing loss/accuracy curves</li> <li>Create interactive attribution graph visualizers</li> <li>Implement feature activation pattern visualization</li> </ul> <p>Milestones: - \u2705 Successfully extract interpretable circuits from at least 5 different algorithmic tasks - \u2705 Operational database with 20+ cataloged circuits - \u2705 Interactive visualization tools for exploring circuits</p>"},{"location":"roadmap/#phase-4-modular-composition-rd-months-10-12","title":"Phase 4: Modular Composition R&amp;D (Months 10-12+)","text":"<p>In this phase, we focus on composing circuits to solve more complex tasks:</p>"},{"location":"roadmap/#interface-definition-standardization","title":"Interface Definition &amp; Standardization","text":"<ul> <li>Analyze extracted representations to understand interface characteristics</li> <li>Define standards/methods for circuit interfaces</li> <li>Document interface requirements in the database</li> </ul>"},{"location":"roadmap/#composition-engine-v01","title":"Composition Engine v0.1","text":"<ul> <li>Develop prototype methods for composing 2-3 circuits functionally</li> <li>Implement hardcoded static pipelines for testing</li> <li>Validate on slightly more complex tasks (e.g., <code>(a+b)*c</code>)</li> </ul>"},{"location":"roadmap/#code-representation-v01","title":"Code Representation v0.1","text":"<ul> <li>Experiment with representing compositions in a code-like format</li> <li>Develop a simple DSL (Domain-Specific Language) for circuit composition</li> <li>Create parsers/interpreters for the composition language</li> </ul>"},{"location":"roadmap/#validation-intervention","title":"Validation &amp; Intervention","text":"<ul> <li>Develop methods to validate composed circuits</li> <li>Implement targeted testing and intervention experiments</li> <li>Create tools for patching intermediate results</li> </ul>"},{"location":"roadmap/#llm-integration-exploratory","title":"LLM Integration (Exploratory)","text":"<ul> <li>Begin experiments using LLMs to query the circuit database</li> <li>Test LLM's ability to suggest compositions based on natural language descriptions</li> <li>Explore prompting strategies for effective LLM assistance</li> </ul> <p>Milestones: - \u2705 Demonstrate successful composition of 2+ circuits to solve a new task - \u2705 Working prototype of code-like representation for compositions - \u2705 Initial proof-of-concept for LLM-assisted composition</p>"},{"location":"roadmap/#phase-5-scaling-refinement-automation-ongoing","title":"Phase 5: Scaling, Refinement &amp; Automation (Ongoing)","text":"<p>This ongoing phase focuses on expanding capabilities and increasing automation:</p>"},{"location":"roadmap/#expanded-task-library","title":"Expanded Task Library","text":"<ul> <li>Add more diverse and complex algorithmic problems</li> <li>Generate larger datasets for more challenging tasks</li> <li>Develop curriculum learning approaches</li> </ul>"},{"location":"roadmap/#model-scaling","title":"Model Scaling","text":"<ul> <li>Scale model sizes as needed for more complex tasks</li> <li>Optimize training infrastructure for larger models</li> <li>Investigate scaling relationships for algorithmic learning</li> </ul>"},{"location":"roadmap/#advanced-extraction","title":"Advanced Extraction","text":"<ul> <li>Refine circuit extraction techniques for better interpretability</li> <li>Improve fidelity of extracted circuits</li> <li>Develop automated circuit discovery methods</li> </ul>"},{"location":"roadmap/#sophisticated-composition","title":"Sophisticated Composition","text":"<ul> <li>Develop dynamic routing mechanisms</li> <li>Implement automated interface adaptation</li> <li>Create tools for handling errors and uncertainty in compositions</li> </ul>"},{"location":"roadmap/#enhanced-llm-integration","title":"Enhanced LLM Integration","text":"<ul> <li>Deepen LLM integration for automated composition</li> <li>Implement verification of LLM-suggested compositions</li> <li>Explore LLM generation of glue code for interfaces</li> </ul> <p>Milestones: - Demonstrate solving complex algorithmic tasks beyond individual model capacity - Achieve high automation in circuit extraction and composition - Show robust performance across a diverse set of tasks </p>"},{"location":"components/circuit_database/","title":"Circuit Database and Analysis Framework","text":"<p>The Circuit Database and Analysis Framework is the core of our system, enabling the extraction, cataloging, and composition of neural circuits from trained models.</p>"},{"location":"components/circuit_database/#circuit-extraction-pipeline","title":"Circuit Extraction Pipeline","text":"<p>We implement automated methods to extract interpretable circuits from transformer models:</p>"},{"location":"components/circuit_database/#extraction-techniques","title":"Extraction Techniques","text":"<p>Our system employs two primary extraction methods:</p>"},{"location":"components/circuit_database/#cross-layer-transcoders-clts-via-dictionary-learning","title":"Cross-Layer Transcoders (CLTs) via Dictionary Learning","text":"<ul> <li>Sparse Autoencoders: Train autoencoders (transcoders) to map activations into an interpretable, sparse feature space</li> <li>Parameter Tuning: Explore variations in sparsity penalties, dictionary sizes, and architectures</li> <li>Layer Mapping: Map activations between (or within) layers to isolate computation paths</li> </ul>"},{"location":"components/circuit_database/#attribution-graph-construction","title":"Attribution Graph Construction","text":"<ul> <li>Causal Tracing: Trace influence from inputs to outputs through identified CLT features</li> <li>Attribution Methods: Use techniques like integrated gradients, activation patching, and path patching</li> <li>Graph Pruning: Heavily prune paths to focus on significant, interpretable connections</li> </ul> <p>These techniques allow us to identify the specific subnetworks responsible for algorithmic computations within the larger model.</p>"},{"location":"components/circuit_database/#centralized-circuit-database","title":"Centralized Circuit Database","text":"<p>We design and implement a structured database for storing and retrieving neural circuits:</p>"},{"location":"components/circuit_database/#database-schema","title":"Database Schema","text":"<p>Our schema includes the following key fields:</p> <ul> <li><code>circuit_id</code>: Unique identifier for the circuit instance</li> <li><code>task_name</code>: The specific algorithmic task (e.g., <code>add_mod_97</code>, <code>grid_rotate_90</code>)</li> <li><code>task_description</code>: Human-readable description and parameters</li> <li><code>model_architecture</code>: Base model details (layers, width), optimizations used, pruning level, parameter count</li> <li><code>training_details</code>: Key hyperparameters, dataset split, training steps to generalization</li> <li><code>circuit_structure</code>: Representation of the identified circuit components (nodes, connections, weights)</li> <li><code>interpretation</code>: Human-readable label and semantic description of the circuit's function</li> <li><code>activation_examples</code>: Representative input examples that strongly activate the circuit</li> <li><code>performance_metrics</code>: Fidelity/accuracy of the isolated circuit</li> <li><code>interface_definition</code>: Description of the circuit's input/output interface (crucial for composition)</li> <li><code>metadata</code>: Pointers to source code, relevant papers, validation results, date extracted</li> </ul>"},{"location":"components/circuit_database/#circuit-tagging-system","title":"Circuit Tagging System","text":"<p>We implement a tagging system to categorize circuits by:</p> <ul> <li>Prior Alignment: <code>Core_Object</code>, <code>Core_Geometry</code>, <code>Core_Number</code>, <code>Core_Topology</code>, etc.</li> <li>Complexity: <code>Primitive</code>, <code>Compound</code>, <code>Highly_Specialized</code></li> <li>Generality: Quantitative scores based on cross-task validation</li> </ul>"},{"location":"components/circuit_database/#visualization-tools","title":"Visualization Tools","text":"<p>We develop interactive visualization tools for exploring and understanding circuits:</p> <ul> <li>Attribution Graph Visualization: Tools to explore paths and node details</li> <li>Feature Activation Explorer: View activation patterns across different inputs</li> <li>Circuit Comparison Views: Side-by-side comparison of different circuits</li> <li>Database Query Interface: User-friendly interface for searching and filtering circuits</li> </ul>"},{"location":"components/circuit_database/#modular-composition-framework","title":"Modular Composition Framework","text":"<p>The modular composition framework treats circuits as reusable functional modules:</p>"},{"location":"components/circuit_database/#standardized-interfaces","title":"Standardized Interfaces","text":"<p>To enable composition, we define standards for circuit communication:</p> <ul> <li>Common Representation Spaces: Attempt to enforce shared representation during CLT training</li> <li>Adapter Networks: Use learned transformations or small adapters between composed modules</li> <li>Normalization Layers: Apply normalization (e.g., LayerNorm) at circuit boundaries</li> <li>Interface Documentation: Clearly document requirements in the database</li> </ul>"},{"location":"components/circuit_database/#composition-engine","title":"Composition Engine","text":"<p>We develop mechanisms to functionally chain circuits:</p>"},{"location":"components/circuit_database/#static-composition","title":"Static Composition","text":"<p>Define fixed graphs of circuit connections for specific complex tasks: <pre><code>output = circuit_B(circuit_A(input))\n</code></pre></p>"},{"location":"components/circuit_database/#dynamic-composition","title":"Dynamic Composition","text":"<p>Implement a meta-controller (potentially LLM-based) to select and route between circuits based on input or intermediate state.</p>"},{"location":"components/circuit_database/#code-like-representation","title":"\"Code-like\" Representation","text":"<p>We explore representing composed circuits in a human-readable format:</p> <pre><code># Example of a code-like representation for (a*b + c) / 2\n\ndef compute_expression(a, b, c):\n    # Circuit IDs are retrieved from DB\n    multiply_circuit = get_circuit_by_id('mul_mod_p_v1')\n    add_circuit = get_circuit_by_id('add_mod_p_v2')\n    halve_circuit = get_circuit_by_id('halve_int_v1')\n\n    # Execute composition pipeline\n    intermediate1 = multiply_circuit(a, b)\n    intermediate2 = add_circuit(intermediate1, c)\n    result = halve_circuit(intermediate2)\n    return result\n</code></pre>"},{"location":"components/circuit_database/#llm-assistance-for-composition","title":"LLM Assistance for Composition","text":"<p>We investigate using modern LLMs (e.g., GPT-4, Claude 3) to assist with:</p> <ul> <li>Suggesting Compositions: Given a task description and circuit database, propose compositions</li> <li>Verifying Correctness: Analyze proposed composition plans for logical soundness</li> <li>Translating Descriptions: Convert natural language algorithm descriptions to code-like circuit compositions</li> <li>Generating Adapters: Create \"glue code\" for interface compatibility</li> </ul>"},{"location":"components/circuit_database/#implementation","title":"Implementation","text":"<p>Our current implementation provides a simple version of the circuit database:</p> <pre><code>class CircuitDatabase:\n    def __init__(self, db_path=\"circuits.db\"):\n        \"\"\"Initialize database connection\"\"\"\n        self.db_path = db_path\n        self._initialize_db()\n\n    def _initialize_db(self):\n        \"\"\"Create database schema if it doesn't exist\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n\n        # Create circuits table\n        cursor.execute('''\n        CREATE TABLE IF NOT EXISTS circuits (\n            circuit_id TEXT PRIMARY KEY,\n            task_name TEXT NOT NULL,\n            task_description TEXT,\n            model_architecture TEXT NOT NULL,\n            training_details TEXT,\n            circuit_structure TEXT,\n            interpretation TEXT,\n            interface_definition TEXT,\n            metadata TEXT,\n            creation_date TEXT,\n            fidelity REAL,\n            extraction_method TEXT\n        )\n        ''')\n\n        # Create additional tables for tags, activation examples, etc.\n        # ...\n\n        conn.commit()\n        conn.close()\n\n    def add_circuit(self, circuit_id, task_name, model_architecture, circuit_structure, \n                   interface_definition, task_description=None, training_details=None, \n                   interpretation=None, metadata=None, fidelity=None, \n                   extraction_method=None, tags=None):\n        \"\"\"Add a new circuit to the database\"\"\"\n        # Implementation for adding circuits\n        # ...\n\n    def query_circuits(self, task_name=None, tags=None, min_fidelity=None, \n                      extraction_method=None, keyword=None):\n        \"\"\"Query circuits based on various criteria\"\"\"\n        # Implementation for querying circuits\n        # ...\n</code></pre>"},{"location":"components/circuit_database/#future-directions","title":"Future Directions","text":"<p>Future work on the circuit database and analysis framework includes:</p> <ol> <li>Advanced Extraction Techniques: Implement more sophisticated circuit extraction methods</li> <li>Interface Standardization: Develop rigorous standards for circuit interfaces</li> <li>Automated Discovery: Tools to automatically identify and extract circuits from trained models</li> <li>Composition Verification: Methods to verify the correctness of composed circuits</li> <li>LLM Integration: Deeper integration with LLMs for automated composition and analysis </li> </ol>"},{"location":"components/data_generation/","title":"Data Generation Module","text":"<p>The Data Generation Module is responsible for automatically creating structured datasets for a wide range of algorithmic tasks. These datasets serve as the foundation for training our transformer models and extracting algorithmic neural circuits.</p>"},{"location":"components/data_generation/#key-features","title":"Key Features","text":"<ul> <li>Diverse Algorithmic Task Generation: Create datasets spanning from simple operations to complex algorithmic challenges</li> <li>Parameterized Generation: Control dataset characteristics like complexity, size, and representation</li> <li>Novel Task Synthesis: Automatically create new tasks by combining existing primitives</li> </ul>"},{"location":"components/data_generation/#algorithmic-task-library","title":"Algorithmic Task Library","text":"<p>The module maintains and expands a library of primitive functions implementing various algorithmic operations:</p>"},{"location":"components/data_generation/#arithmetic-operations","title":"Arithmetic Operations","text":"<ul> <li><code>add</code>, <code>subtract</code>, <code>multiply</code>, <code>divide</code> (integer, modular, tuple-based)</li> <li>Example: Modular addition <code>(a + b) % n</code></li> </ul>"},{"location":"components/data_generation/#logical-operations","title":"Logical Operations","text":"<ul> <li><code>even</code>, <code>flip</code>, <code>both</code>, <code>either</code>, <code>positive</code>, <code>equality</code></li> <li>Example: Boolean operations like <code>a AND b</code></li> </ul>"},{"location":"components/data_generation/#setcontainer-operations","title":"Set/Container Operations","text":"<ul> <li><code>combine</code>, <code>intersection</code>, <code>difference</code>, <code>dedupe</code>, <code>order</code>, <code>size</code>, <code>filter</code></li> <li>Example: Set operations like union and intersection</li> </ul>"},{"location":"components/data_generation/#gridpatch-manipulations","title":"Grid/Patch Manipulations","text":"<ul> <li>Based on <code>arc_types</code> primitives</li> <li><code>rot90</code>, <code>hmirror</code>, <code>crop</code>, <code>objects</code>, <code>fill</code>, <code>upscale</code></li> <li>Example: Rotating or reflecting shapes in a grid</li> </ul>"},{"location":"components/data_generation/#sequence-operations","title":"Sequence Operations","text":"<ul> <li><code>dedupe</code>, <code>order</code>, simple string edits</li> <li>Example: Removing duplicates from a sequence</li> </ul>"},{"location":"components/data_generation/#structured-dataset-generator","title":"Structured Dataset Generator","text":"<p>The Structured Dataset Generator creates formatted datasets ready for training:</p> <ul> <li>Input/Output Format: Generates sequences like \"Input: a OP b | Output: c\" or more complex grid structures</li> <li>Binary Operation Tables: Focus on tasks like <code>a \u25e6 b = c</code> (modular arithmetic, group operations) for grokking studies</li> <li>Parameterization:</li> <li>Task complexity (modulus size, grid dimensions)</li> <li>Input/output representations (base 10 vs. symbolic tokens, grid serialization)</li> <li>Dataset splits (e.g., 50% train for grokking studies)</li> <li>Optional noise or outlier injection</li> </ul>"},{"location":"components/data_generation/#novel-task-synthesis-engine","title":"Novel Task Synthesis Engine","text":"<p>The Novel Task Synthesis Engine creates new, potentially more complex tasks:</p> <ul> <li>Composition: Generate new tasks by composing primitive functions (e.g., <code>f(x,y,z) = add(multiply(x,y), z)</code>)</li> <li>Validation Checks: Ensure generated tasks are:</li> <li>Well-posed and solvable within defined constraints</li> <li>Non-trivial (not solvable by simple heuristics)</li> <li>Suitable for probing specific reasoning capabilities</li> </ul>"},{"location":"components/data_generation/#implementation","title":"Implementation","text":"<p>Our current implementation focuses on binary operations, particularly modular arithmetic. Below is an example of modular addition data generation:</p> <pre><code>def generate_modular_addition_data(modulus: int, train_ratio: float = 0.5):\n    \"\"\"\n    Generate a dataset for modular addition: (a + b) % modulus\n\n    Args:\n        modulus: The modulus for the addition operation\n        train_ratio: Fraction of examples to use for training\n\n    Returns:\n        Dictionary containing input and target tensors for train and test sets\n    \"\"\"\n    # Generate all possible a,b pairs\n    all_pairs = [(a, b) for a in range(modulus) for b in range(modulus)]\n    all_inputs = torch.tensor(all_pairs, dtype=torch.long)\n\n    # Calculate targets: (a + b) % modulus\n    all_targets = (all_inputs[:, 0] + all_inputs[:, 1]) % modulus\n\n    # Shuffle and split into train and test\n    indices = torch.randperm(len(all_pairs))\n    all_inputs = all_inputs[indices]\n    all_targets = all_targets[indices]\n\n    train_size = int(len(all_pairs) * train_ratio)\n\n    return {\n        \"train_inputs\": all_inputs[:train_size],\n        \"train_targets\": all_targets[:train_size],\n        \"test_inputs\": all_inputs[train_size:],\n        \"test_targets\": all_targets[train_size:]\n    }\n</code></pre>"},{"location":"components/data_generation/#future-directions","title":"Future Directions","text":"<p>Future work on the Data Generation Module includes:</p> <ol> <li>Expanded Primitive Library: Implement more diverse algorithmic primitives</li> <li>Multi-Step Tasks: Generate tasks requiring multi-step reasoning</li> <li>Task Difficulty Metrics: Develop methods to quantify and control task complexity</li> <li>Curriculum Generation: Create progressive task sequences of increasing difficulty</li> <li>Adversarial Examples: Generate challenging edge cases to test model robustness </li> </ol>"},{"location":"components/explanation/","title":"Explanation and Interpretability","text":"<p>This document outlines our approach to making neural network transformations interpretable, explainable, and composable through circuit extraction and analysis.</p>"},{"location":"components/explanation/#principles-of-neural-interpretability","title":"Principles of Neural Interpretability","text":"<p>Our framework is built on these core principles:</p> <ol> <li>Mechanistic Interpretability: Understanding the causal mechanisms within neural networks, not just input-output correlations</li> <li>Composition-based Explanations: Describing network behavior as compositions of simpler, meaningful circuits</li> <li>Human-aligned Concepts: Developing interpretations that align with human conceptual understanding</li> <li>Falsifiability: Creating explanations that make testable predictions about model behavior</li> </ol>"},{"location":"components/explanation/#extraction-methodologies","title":"Extraction Methodologies","text":"<p>Our system employs multiple complementary techniques:</p>"},{"location":"components/explanation/#1-cross-layer-transcoders-clts","title":"1. Cross-Layer Transcoders (CLTs)","text":"<p>CLTs use dictionary learning to identify meaningful dimensions in model activations:</p> <pre><code>class CrossLayerTranscoder:\n    def __init__(self, source_layer, target_layer, dictionary_size=100):\n        self.source_layer = source_layer\n        self.target_layer = target_layer\n        self.dictionary_size = dictionary_size\n        self.dictionary = None\n\n    def train(self, activations_dataset):\n        \"\"\"Train the transcoder dictionary on activation pairs.\"\"\"\n        # Dictionary learning implementation\n        source_activations = [data[self.source_layer] for data in activations_dataset]\n        target_activations = [data[self.target_layer] for data in activations_dataset]\n\n        # Use sparse coding / dictionary learning algorithm\n        self.dictionary = train_dictionary(source_activations, target_activations, \n                                          self.dictionary_size)\n\n    def decode_circuit(self, circuit_idx):\n        \"\"\"Extract the circuit corresponding to dictionary element at circuit_idx.\"\"\"\n        # Return the weights and structure of the identified circuit\n</code></pre> <p>Key capabilities: - Identifies information flows between layers - Reveals learned feature hierarchies  - Reduces dimensionality to human-interpretable concepts</p>"},{"location":"components/explanation/#2-attribution-graph-construction","title":"2. Attribution Graph Construction","text":"<p>We build attribution graphs to trace causal pathways through the network:</p> <pre><code>def build_attribution_graph(model, input_example, target_output_node):\n    \"\"\"Build a graph of attribution scores between model components.\"\"\"\n    graph = nx.DiGraph()\n\n    # Initialize with all nodes in the model\n    for layer_idx, layer in enumerate(model.layers):\n        for neuron_idx in range(layer.output_size):\n            graph.add_node((layer_idx, neuron_idx))\n\n    # Calculate causal attribution between connected nodes\n    for layer_idx in range(len(model.layers) - 1):\n        source_layer = model.layers[layer_idx]\n        target_layer = model.layers[layer_idx + 1]\n\n        for source_idx in range(source_layer.output_size):\n            for target_idx in range(target_layer.output_size):\n                attribution = calculate_causal_attribution(\n                    model, input_example, (layer_idx, source_idx), (layer_idx+1, target_idx)\n                )\n                if attribution &gt; THRESHOLD:\n                    graph.add_edge((layer_idx, source_idx), (layer_idx+1, target_idx), \n                                  weight=attribution)\n\n    return graph\n</code></pre> <p>Key features: - Provides causal understanding of information flow - Identifies critical pathways for specific behaviors - Supports pruning to isolate essential components</p>"},{"location":"components/explanation/#3-iterative-circuit-refinement","title":"3. Iterative Circuit Refinement","text":"<p>We employ a systematic process for refining circuit understanding:</p> <ol> <li>Hypothesis Generation: Use dictionary learning to identify candidate circuits</li> <li>Causal Validation: Test causal effects by intervening on activations </li> <li>Refinement: Iteratively refine circuit boundaries and connections</li> <li>Documentation: Create human-readable descriptions with examples and counter-examples</li> </ol>"},{"location":"components/explanation/#interpretability-database-schema","title":"Interpretability Database Schema","text":"<p>Our database stores interpreted circuits with these fields:</p> Field Description Example <code>circuit_id</code> Unique identifier <code>\"obj_translation_circuit_v2\"</code> <code>human_concept</code> Conceptual interpretation <code>\"Object translation/movement detector\"</code> <code>formal_description</code> Mathematical description <code>\"Computes translation vector between frames\"</code> <code>evidence</code> Supporting evidence <code>[{test_type: \"activation\", result: \"...\"}]</code> <code>counter_examples</code> Cases where interpretation fails <code>[{input: \"...\", expected: \"...\", actual: \"...\"}]</code> <code>visualization</code> Circuit visualization <code>\"path/to/visualization.html\"</code> <code>composition</code> Component subcircuits <code>[\"edge_detector_v1\", \"motion_integrator_v3\"]</code>"},{"location":"components/explanation/#explanation-generation-system","title":"Explanation Generation System","text":"<p>Our explanation system generates human-understandable descriptions:</p>"},{"location":"components/explanation/#components","title":"Components","text":"<ol> <li>Circuit Analyzer: Extracts statistical properties of circuit behavior</li> <li>Natural Language Generator: Converts circuit analysis to human language</li> <li>Example Selector: Chooses representative examples demonstrating the circuit</li> <li>Visualization Engine: Creates visual representations of circuit function</li> </ol>"},{"location":"components/explanation/#explanation-types","title":"Explanation Types","text":"<p>We generate multiple types of explanations:</p> <ol> <li>Functional Explanations: What the circuit computes (e.g., \"This circuit detects vertical edges in the input\")</li> <li>Mechanistic Explanations: How the circuit implements its function (e.g., \"The circuit combines outputs from neurons 47-52 which act as Gabor filters\")</li> <li>Behavioral Explanations: When and how the circuit activates (e.g., \"This circuit strongly activates when vertical lines appear in the bottom left quadrant\")</li> <li>Compositional Explanations: How the circuit relates to other circuits (e.g., \"This circuit builds on the basic edge detector to implement rotation invariance\")</li> </ol>"},{"location":"components/explanation/#interactive-exploration-tools","title":"Interactive Exploration Tools","text":"<p>Our system includes tools for interactively exploring circuits:</p>"},{"location":"components/explanation/#1-circuit-browser","title":"1. Circuit Browser","text":"<p>An interactive interface for exploring the circuit database:</p> <pre><code>class CircuitBrowser:\n    def __init__(self, circuit_db):\n        self.circuit_db = circuit_db\n\n    def search(self, query):\n        \"\"\"Search for circuits matching the query.\"\"\"\n        return self.circuit_db.search(query)\n\n    def visualize(self, circuit_id):\n        \"\"\"Generate interactive visualization for the circuit.\"\"\"\n        circuit = self.circuit_db.get(circuit_id)\n        return self.generate_visualization(circuit)\n\n    def analyze_behavior(self, circuit_id, test_inputs):\n        \"\"\"Analyze circuit behavior on test inputs.\"\"\"\n        circuit = self.circuit_db.get(circuit_id)\n        return {input_id: circuit.activate(input_val) for input_id, input_val in test_inputs.items()}\n</code></pre>"},{"location":"components/explanation/#2-explanation-dashboard","title":"2. Explanation Dashboard","text":"<p>A dashboard for generating and customizing explanations:</p> <ul> <li>Select explanation detail level (simple/detailed)</li> <li>Choose explanation type (functional/mechanistic/etc.)</li> <li>Toggle between different visualization styles</li> <li>Compare explanations across multiple circuits</li> </ul>"},{"location":"components/explanation/#testing-and-validation","title":"Testing and Validation","text":"<p>We rigorously validate our interpretations:</p>"},{"location":"components/explanation/#intervention-testing","title":"Intervention Testing","text":"<p>We test circuit interpretations by intervening in the network:</p> <pre><code>def validate_circuit_interpretation(model, circuit, interpretation, test_cases):\n    \"\"\"Validate whether a circuit interpretation is correct through interventions.\"\"\"\n    results = []\n\n    for test_case in test_cases:\n        # Get base model prediction\n        base_prediction = model(test_case.input)\n\n        # Create intervention according to our interpretation\n        intervention = create_intervention(circuit, interpretation, test_case)\n\n        # Apply intervention and get new prediction\n        intervention_prediction = apply_intervention_and_predict(model, circuit, intervention, test_case.input)\n\n        # Check if results match our hypothesis\n        matches_hypothesis = test_intervention_hypothesis(\n            interpretation, test_case, base_prediction, intervention_prediction\n        )\n\n        results.append({\n            \"test_case\": test_case.id,\n            \"matches_hypothesis\": matches_hypothesis,\n            \"details\": {\n                \"base_prediction\": base_prediction,\n                \"intervention_prediction\": intervention_prediction,\n                \"expected_change\": test_case.expected_change\n            }\n        })\n\n    return results\n</code></pre>"},{"location":"components/explanation/#falsification-challenges","title":"Falsification Challenges","text":"<p>We actively attempt to falsify our interpretations:</p> <ol> <li>Adversarial Inputs: Generating inputs designed to break the interpretation</li> <li>Edge Cases: Testing circuit behavior on boundary conditions</li> <li>Counterfactual Analysis: Testing \"what if\" scenarios based on the interpretation</li> </ol>"},{"location":"components/explanation/#human-ai-collaborative-interpretation","title":"Human-AI Collaborative Interpretation","text":"<p>We leverage both human insight and AI capabilities:</p>"},{"location":"components/explanation/#the-human-role","title":"The Human Role","text":"<ul> <li>Providing conceptual frameworks and hypotheses</li> <li>Evaluation of interpretation quality and usefulness</li> <li>Suggesting refinements based on domain knowledge</li> </ul>"},{"location":"components/explanation/#the-ai-role","title":"The AI Role","text":"<ul> <li>Systematic exploration of network internals</li> <li>Pattern recognition across numerous activations</li> <li>Formalization of interpretations into testable predictions</li> </ul>"},{"location":"components/explanation/#implementation-status","title":"Implementation Status","text":"<p>Current status of implementation:</p> <ul> <li>Basic Dictionary Learning: Implemented (v0.8)</li> <li>Attribution Graph Construction: Implemented (v0.6)</li> <li>Explanation Generation: Partial implementation (v0.4)</li> <li>Interactive Tools: Prototype stage (v0.2)</li> <li>Validation Framework: Design phase</li> </ul>"},{"location":"components/explanation/#future-directions","title":"Future Directions","text":"<p>Our roadmap for future development:</p> <ol> <li>Multi-Modal Interpretations: Extending techniques to vision-language models</li> <li>Causal Tracing Improvements: Better handling of indirect causal effects</li> <li>Automated Refinement: Developing systems to automatically refine interpretations</li> <li>Interpretation Benchmarks: Creating standardized evaluation frameworks</li> <li>Cross-Model Translation: Mapping interpretations between different model architectures </li> </ol>"},{"location":"components/modular_composition/","title":"Modular Circuit Composition","text":"<p>This document details our framework for composing extracted neural circuits into novel, functionally complex systems.</p>"},{"location":"components/modular_composition/#core-principles","title":"Core Principles","text":"<p>Our modular composition framework is built on these foundational principles:</p> <ol> <li>Compositionality: Neural circuits can be meaningfully combined to create more complex functionality</li> <li>Interface Standardization: Well-defined interfaces enable reliable circuit connection</li> <li>Functional Preservation: Composed circuits maintain core functionality from their original contexts</li> <li>Emergent Behavior: Novel capabilities can emerge from composition of simpler circuits</li> </ol>"},{"location":"components/modular_composition/#circuit-interface-definition","title":"Circuit Interface Definition","text":"<p>Each circuit in our system has standardized interfaces:</p> <pre><code>class CircuitInterface:\n    def __init__(self, name, input_dims, output_dims, activation_constraints=None):\n        self.name = name\n        self.input_dims = input_dims  # Dict mapping input names to shapes\n        self.output_dims = output_dims  # Dict mapping output names to shapes\n        self.activation_constraints = activation_constraints or {}  # Optional constraints\n\n    def is_compatible_with(self, other_interface, connection_point):\n        \"\"\"Check if this interface is compatible with another at the given connection point.\"\"\"\n        if connection_point not in self.output_dims or connection_point not in other_interface.input_dims:\n            return False\n\n        # Check dimension compatibility\n        my_output_shape = self.output_dims[connection_point]\n        other_input_shape = other_interface.input_dims[connection_point]\n\n        return my_output_shape == other_input_shape\n</code></pre> <p>Key interface attributes: - Named Inputs/Outputs: Semantic labels for connection points - Dimensional Specifications: Shape requirements for compatible connections - Activation Statistics: Expected distributions and ranges - Functional Contract: Behavioral guarantees provided by the circuit</p>"},{"location":"components/modular_composition/#composition-methods","title":"Composition Methods","text":"<p>Our framework supports several composition patterns:</p>"},{"location":"components/modular_composition/#1-sequential-composition","title":"1. Sequential Composition","text":"<p>Connecting circuits in a feed-forward sequence:</p> <pre><code>def compose_sequential(circuit_a, circuit_b, connection_mapping):\n    \"\"\"Connect circuit_a outputs to circuit_b inputs according to the mapping.\"\"\"\n    if not validate_sequential_compatibility(circuit_a, circuit_b, connection_mapping):\n        raise IncompatibleCircuitsError(\"Circuits cannot be sequentially composed\")\n\n    composed_circuit = ComposedCircuit()\n\n    # Add both circuits to the composition\n    composed_circuit.add_subcircuit(\"A\", circuit_a)\n    composed_circuit.add_subcircuit(\"B\", circuit_b)\n\n    # Create the connections\n    for output_name, input_name in connection_mapping.items():\n        composed_circuit.connect(\n            (\"A\", output_name),\n            (\"B\", input_name)\n        )\n\n    return composed_circuit\n</code></pre>"},{"location":"components/modular_composition/#2-parallel-composition","title":"2. Parallel Composition","text":"<p>Running multiple circuits side-by-side:</p> <pre><code>def compose_parallel(circuits, shared_inputs=None, merged_outputs=None):\n    \"\"\"Compose circuits to run in parallel, optionally sharing inputs and merging outputs.\"\"\"\n    composed_circuit = ComposedCircuit()\n\n    # Add all subcircuits\n    for i, circuit in enumerate(circuits):\n        composed_circuit.add_subcircuit(f\"Sub{i}\", circuit)\n\n    # Connect shared inputs if specified\n    if shared_inputs:\n        for input_name, target_circuits in shared_inputs.items():\n            for target_idx, target_input in target_circuits:\n                composed_circuit.share_input(\n                    input_name,\n                    (f\"Sub{target_idx}\", target_input)\n                )\n\n    # Configure merged outputs if specified\n    if merged_outputs:\n        for output_name, source_outputs in merged_outputs.items():\n            composed_circuit.merge_outputs(\n                output_name,\n                [(f\"Sub{idx}\", output) for idx, output in source_outputs]\n            )\n\n    return composed_circuit\n</code></pre>"},{"location":"components/modular_composition/#3-recurrent-composition","title":"3. Recurrent Composition","text":"<p>Creating feedback loops between circuits:</p> <pre><code>def compose_recurrent(circuit, feedback_connections, max_iterations=10):\n    \"\"\"Create a recurrent composition where outputs feed back into inputs.\"\"\"\n    if not validate_recurrent_compatibility(circuit, feedback_connections):\n        raise IncompatibleCircuitsError(\"Circuit cannot be recurrently composed\")\n\n    composed_circuit = RecurrentComposedCircuit(max_iterations)\n\n    # Add the circuit to be recurrently connected\n    composed_circuit.add_subcircuit(\"Main\", circuit)\n\n    # Create the feedback connections\n    for output_name, input_name in feedback_connections.items():\n        composed_circuit.add_feedback(\n            (\"Main\", output_name),\n            (\"Main\", input_name)\n        )\n\n    return composed_circuit\n</code></pre>"},{"location":"components/modular_composition/#4-hierarchical-composition","title":"4. Hierarchical Composition","text":"<p>Organizing circuits into hierarchical structures:</p> <pre><code>def compose_hierarchical(subcircuits, connections, interface_mapping):\n    \"\"\"Create a hierarchical composition of subcircuits.\"\"\"\n    hierarchical_circuit = HierarchicalCircuit()\n\n    # Add all subcircuits\n    for name, circuit in subcircuits.items():\n        hierarchical_circuit.add_subcircuit(name, circuit)\n\n    # Create internal connections\n    for (source_name, source_output), (target_name, target_input) in connections:\n        hierarchical_circuit.connect(\n            (source_name, source_output),\n            (target_name, target_input)\n        )\n\n    # Define the external interface\n    for external_name, (circuit_name, internal_name) in interface_mapping.items():\n        hierarchical_circuit.map_interface(external_name, (circuit_name, internal_name))\n\n    return hierarchical_circuit\n</code></pre>"},{"location":"components/modular_composition/#adaptation-mechanisms","title":"Adaptation Mechanisms","text":"<p>Our system includes several techniques to adapt circuits for composition:</p>"},{"location":"components/modular_composition/#1-activation-adapters","title":"1. Activation Adapters","text":"<p>Small learned networks that transform activations between incompatible circuits:</p> <pre><code>class ActivationAdapter:\n    def __init__(self, source_dims, target_dims, adapter_type=\"mlp\"):\n        self.source_dims = source_dims\n        self.target_dims = target_dims\n        self.adapter_type = adapter_type\n        self.adapter_network = self._create_adapter_network()\n\n    def _create_adapter_network(self):\n        \"\"\"Create the appropriate adapter network based on type and dimensions.\"\"\"\n        if self.adapter_type == \"mlp\":\n            return MLP(\n                input_size=np.prod(self.source_dims),\n                hidden_sizes=[100, 100],\n                output_size=np.prod(self.target_dims),\n                activation=nn.ReLU()\n            )\n        elif self.adapter_type == \"linear\":\n            return nn.Linear(np.prod(self.source_dims), np.prod(self.target_dims))\n        # Other adapter types...\n\n    def transform(self, source_activation):\n        \"\"\"Transform activations from source to target dimensions.\"\"\"\n        # Flatten, transform, reshape\n        flattened = source_activation.reshape(-1)\n        transformed = self.adapter_network(flattened)\n        return transformed.reshape(self.target_dims)\n\n    def train(self, source_examples, target_examples, optimizer, loss_fn, epochs=100):\n        \"\"\"Train the adapter to map between source and target examples.\"\"\"\n        # Training implementation\n</code></pre>"},{"location":"components/modular_composition/#2-distribution-matching","title":"2. Distribution Matching","text":"<p>Ensuring activation distributions are compatible between circuits:</p> <pre><code>def match_distributions(source_circuit, target_circuit, connection_point, calibration_dataset):\n    \"\"\"Create a distribution matching function for connecting circuits.\"\"\"\n    # Collect activation statistics\n    source_activations = collect_activations(source_circuit, calibration_dataset, connection_point)\n    target_activations = collect_activations(target_circuit, calibration_dataset, connection_point)\n\n    # Compute source statistics\n    source_mean = np.mean(source_activations, axis=0)\n    source_std = np.std(source_activations, axis=0)\n\n    # Compute target statistics\n    target_mean = np.mean(target_activations, axis=0)\n    target_std = np.std(target_activations, axis=0)\n\n    # Create transformation function\n    def transform_activation(activation):\n        # Normalize to z-scores using source statistics\n        normalized = (activation - source_mean) / (source_std + 1e-8)\n        # Scale to target distribution\n        return normalized * target_std + target_mean\n\n    return transform_activation\n</code></pre>"},{"location":"components/modular_composition/#3-prompting-based-adapters","title":"3. Prompting-Based Adapters","text":"<p>Using LLMs to generate adapter code:</p> <pre><code>def generate_adapter_with_llm(source_circuit, target_circuit, connection_point, examples, llm):\n    \"\"\"Use an LLM to generate adapter code based on examples.\"\"\"\n    # Create prompt with context and examples\n    prompt = f\"\"\"\n    I need to create an adapter function that converts the output from \n    \"{source_circuit.name}\" at \"{connection_point}\" to be compatible with \n    the input of \"{target_circuit.name}\" at the same connection point.\n\n    Source circuit output: {source_circuit.interface.output_dims[connection_point]}\n    Target circuit input: {target_circuit.interface.input_dims[connection_point]}\n\n    Here are some example pairs of activations (source \u2192 target):\n    \"\"\"\n\n    for source_act, target_act in examples:\n        prompt += f\"\\nSource: {source_act}\\nTarget: {target_act}\\n\"\n\n    prompt += \"\\nWrite a Python function that performs this conversion:\"\n\n    # Get code from LLM\n    adapter_code = llm.generate_code(prompt)\n\n    # Compile and return the function\n    adapter_function = compile_function_from_code(adapter_code)\n    return adapter_function\n</code></pre>"},{"location":"components/modular_composition/#llm-assisted-composition","title":"LLM-Assisted Composition","text":"<p>Our framework leverages LLM capabilities to aid circuit composition:</p>"},{"location":"components/modular_composition/#1-interface-inference","title":"1. Interface Inference","text":"<pre><code>def infer_circuit_interface(circuit_code, circuit_name, llm):\n    \"\"\"Use LLM to infer a circuit's interface from its code.\"\"\"\n    prompt = f\"\"\"\n    Analyze the following neural circuit code and identify its interface.\n    Determine the input/output tensor dimensions and semantics.\n\n    Circuit name: {circuit_name}\n\n    Code:\n    {circuit_code}\n\n    Return a JSON object with the following structure:\n    {{\n        \"inputs\": [\n            {{\"name\": \"input_name\", \"dimensions\": [dim1, dim2, ...], \"semantics\": \"description\"}}\n        ],\n        \"outputs\": [\n            {{\"name\": \"output_name\", \"dimensions\": [dim1, dim2, ...], \"semantics\": \"description\"}}\n        ]\n    }}\n    \"\"\"\n\n    interface_json = llm.generate_json(prompt)\n    return CircuitInterface.from_json(interface_json)\n</code></pre>"},{"location":"components/modular_composition/#2-composition-planning","title":"2. Composition Planning","text":"<pre><code>def plan_composition(available_circuits, target_description, llm):\n    \"\"\"Use LLM to plan how to compose available circuits to achieve a target function.\"\"\"\n    # Create circuit catalog\n    circuit_catalog = \"\\n\".join([\n        f\"Circuit: {circuit.name}\\n\"\n        f\"Function: {circuit.description}\\n\"\n        f\"Inputs: {circuit.interface.input_dims}\\n\"\n        f\"Outputs: {circuit.interface.output_dims}\\n\"\n        for circuit in available_circuits\n    ])\n\n    prompt = f\"\"\"\n    I have the following neural circuits available:\n\n    {circuit_catalog}\n\n    I want to create a composed circuit that: {target_description}\n\n    Provide a composition plan with the following:\n    1. Which circuits to use\n    2. How to connect them (sequential, parallel, recurrent, or hierarchical)\n    3. Any adapter functions needed for compatibility\n    4. The expected functionality of the final composed circuit\n\n    Return the plan in JSON format.\n    \"\"\"\n\n    composition_plan = llm.generate_json(prompt)\n    return composition_plan\n</code></pre>"},{"location":"components/modular_composition/#3-adapter-generation","title":"3. Adapter Generation","text":"<pre><code>def generate_adapter(source_circuit, target_circuit, connection_point, llm):\n    \"\"\"Use LLM to generate an adapter between two circuits.\"\"\"\n    prompt = f\"\"\"\n    I need to connect the output '{connection_point}' from {source_circuit.name} \n    to the input '{connection_point}' of {target_circuit.name}.\n\n    Source output shape: {source_circuit.interface.output_dims[connection_point]}\n    Target input shape: {target_circuit.interface.input_dims[connection_point]}\n\n    Source circuit function: {source_circuit.description}\n    Target circuit function: {target_circuit.description}\n\n    Generate Python code for an adapter function that will transform the source output\n    to be compatible with the target input. The function should have the signature:\n\n    def adapter(source_activation):\n        # transformation code\n        return transformed_activation\n    \"\"\"\n\n    adapter_code = llm.generate_code(prompt)\n    adapter_function = compile_function_from_code(adapter_code)\n    return adapter_function\n</code></pre>"},{"location":"components/modular_composition/#testing-and-validation","title":"Testing and Validation","text":"<p>Our framework includes tools for testing composed circuits:</p>"},{"location":"components/modular_composition/#functional-testing","title":"Functional Testing","text":"<pre><code>def test_composed_circuit(composed_circuit, test_cases):\n    \"\"\"Test a composed circuit against expected behaviors.\"\"\"\n    results = []\n\n    for test_case in test_cases:\n        # Run the circuit on the test input\n        actual_output = composed_circuit(test_case.input)\n\n        # Check if output matches expected\n        success = is_output_matching(actual_output, test_case.expected_output)\n\n        results.append({\n            \"test_case\": test_case.id,\n            \"success\": success,\n            \"expected\": test_case.expected_output,\n            \"actual\": actual_output,\n            \"error_margin\": calculate_error(actual_output, test_case.expected_output)\n        })\n\n    return results\n</code></pre>"},{"location":"components/modular_composition/#composition-validation","title":"Composition Validation","text":"<pre><code>def validate_composition(composition_plan, available_circuits):\n    \"\"\"Validate that a composition plan is feasible with the available circuits.\"\"\"\n    validation_results = {\n        \"is_valid\": True,\n        \"issues\": []\n    }\n\n    # Check that all referenced circuits exist\n    for circuit_ref in composition_plan.get_circuit_references():\n        if not circuit_exists(circuit_ref, available_circuits):\n            validation_results[\"is_valid\"] = False\n            validation_results[\"issues\"].append(f\"Referenced circuit '{circuit_ref}' not found\")\n\n    # Check interface compatibility\n    for connection in composition_plan.get_connections():\n        source_circuit = get_circuit(connection.source_circuit, available_circuits)\n        target_circuit = get_circuit(connection.target_circuit, available_circuits)\n\n        if not are_interfaces_compatible(\n            source_circuit, target_circuit, \n            connection.source_point, connection.target_point\n        ):\n            validation_results[\"is_valid\"] = False\n            validation_results[\"issues\"].append(\n                f\"Incompatible connection from {connection.source_circuit}.{connection.source_point} \"\n                f\"to {connection.target_circuit}.{connection.target_point}\"\n            )\n\n    return validation_results\n</code></pre>"},{"location":"components/modular_composition/#implementation-status","title":"Implementation Status","text":"<p>Current status of implementation:</p> <ul> <li>Basic Composition Framework: Implemented (v0.7)</li> <li>Sequential &amp; Parallel Composition: Implemented (v0.8)</li> <li>Recurrent &amp; Hierarchical Composition: Prototype (v0.4)</li> <li>LLM-Assisted Composition: Early development (v0.3)</li> <li>Validation Tools: Design phase (v0.2)</li> </ul>"},{"location":"components/modular_composition/#future-directions","title":"Future Directions","text":"<p>Our roadmap for the composition framework:</p> <ol> <li>Self-Adaptive Interfaces: Circuits that automatically adapt to connection partners</li> <li>Composition Verification: Formal verification of circuit compositions</li> <li>Dynamic Reconfiguration: Runtime modification of circuit connections</li> <li>Multi-Objective Optimization: Optimizing compositions for multiple competing objectives </li> <li>Learned Composition Rules: Data-driven approaches to discovering effective composition patterns </li> </ol>"},{"location":"components/scalability/","title":"Scalability Infrastructure","text":"<p>This document outlines our approach to scaling the Neural Circuit Extraction and Modular Composition Framework across multiple dimensions: model size, dataset complexity, training throughput, and circuit analysis.</p>"},{"location":"components/scalability/#core-scalability-principles","title":"Core Scalability Principles","text":"<p>Our architecture is built on these foundational scalability principles:</p> <ol> <li>Horizontal Scalability: Add more compute resources to linearly increase throughput</li> <li>Hierarchical Decomposition: Break large problems into independently solvable subproblems</li> <li>Dynamic Resource Allocation: Allocate compute resources based on task priority and complexity</li> <li>Incremental Processing: Process and store data incrementally rather than requiring full dataset loads</li> <li>Smart Caching: Cache intermediate results strategically to prevent redundant computation</li> </ol>"},{"location":"components/scalability/#distributed-training-infrastructure","title":"Distributed Training Infrastructure","text":"<p>Our training infrastructure scales across multiple nodes:</p>"},{"location":"components/scalability/#distributed-data-parallelism","title":"Distributed Data Parallelism","text":"<pre><code>class DistributedTrainer:\n    def __init__(self, model, optimizer_fn, world_size, rank):\n        self.local_model = model\n        self.world_size = world_size\n        self.rank = rank\n\n        # Wrap model for distributed training\n        self.model = torch.nn.parallel.DistributedDataParallel(\n            self.local_model,\n            device_ids=[rank] if torch.cuda.is_available() else None\n        )\n\n        # Initialize optimizer\n        self.optimizer = optimizer_fn(self.model.parameters())\n\n    def train_epoch(self, dataloader, loss_fn):\n        \"\"\"Train for one epoch with distributed data parallelism.\"\"\"\n        self.model.train()\n        epoch_loss = 0.0\n\n        for batch_idx, (inputs, targets) in enumerate(dataloader):\n            # Move data to appropriate device\n            inputs = inputs.to(self.rank)\n            targets = targets.to(self.rank)\n\n            # Forward pass\n            outputs = self.model(inputs)\n            loss = loss_fn(outputs, targets)\n\n            # Backward pass and optimize\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n\n            # Accumulate loss\n            epoch_loss += loss.item()\n\n        # Average loss across all batches\n        return epoch_loss / len(dataloader)\n</code></pre>"},{"location":"components/scalability/#model-parallelism","title":"Model Parallelism","text":"<p>For very large models that don't fit on a single device:</p> <pre><code>class ModelParallelTransformer:\n    def __init__(self, config, num_devices):\n        self.config = config\n        self.num_devices = num_devices\n\n        # Split layers across devices\n        self.devices = [torch.device(f\"cuda:{i}\") for i in range(num_devices)]\n        layers_per_device = config.num_layers // num_devices\n\n        # Create layer groups\n        self.layer_groups = []\n        for i in range(num_devices):\n            start_layer = i * layers_per_device\n            end_layer = (i + 1) * layers_per_device if i &lt; num_devices - 1 else config.num_layers\n\n            # Create layers for this device\n            device_layers = nn.ModuleList([\n                TransformerLayer(config) \n                for _ in range(start_layer, end_layer)\n            ]).to(self.devices[i])\n\n            self.layer_groups.append(device_layers)\n\n        # Embedding on first device, output on last device\n        self.embedding = TokenEmbedding(config).to(self.devices[0])\n        self.output_layer = OutputLayer(config).to(self.devices[-1])\n\n    def forward(self, input_ids):\n        # Start on first device\n        x = self.embedding(input_ids.to(self.devices[0]))\n\n        # Process through layer groups\n        for device_idx, layers in enumerate(self.layer_groups):\n            for layer in layers:\n                x = layer(x)\n\n            # Transfer to next device if not the last one\n            if device_idx &lt; self.num_devices - 1:\n                next_device = self.devices[device_idx + 1]\n                x = x.to(next_device)\n\n        # Final output projection\n        return self.output_layer(x)\n</code></pre>"},{"location":"components/scalability/#pipeline-parallelism","title":"Pipeline Parallelism","text":"<p>For efficient processing of very deep models:</p> <pre><code>class PipelineParallelTrainer:\n    def __init__(self, partitioned_model, optimizer_fns, num_microbatches=32):\n        self.partitioned_model = partitioned_model  # List of model partitions\n        self.num_stages = len(partitioned_model)\n        self.num_microbatches = num_microbatches\n\n        # Create optimizers for each partition\n        self.optimizers = [\n            opt_fn(model.parameters()) \n            for model, opt_fn in zip(partitioned_model, optimizer_fns)\n        ]\n\n        # Buffers for pipeline parallelism\n        self.activation_buffers = [\n            [None for _ in range(num_microbatches + 1)]\n            for _ in range(self.num_stages + 1)\n        ]\n\n    def train_batch(self, full_batch, loss_fn):\n        \"\"\"Train using pipeline parallelism with gradient accumulation.\"\"\"\n        # Split batch into microbatches\n        microbatches = self._split_batch(full_batch, self.num_microbatches)\n\n        # Zero gradients\n        for opt in self.optimizers:\n            opt.zero_grad()\n\n        # Pipeline forward and backward passes\n        for step in range(2 * self.num_stages + self.num_microbatches - 2):\n            # Determine which microbatches and stages to process\n            for stage in range(self.num_stages):\n                microbatch_idx = step - stage\n\n                if 0 &lt;= microbatch_idx &lt; self.num_microbatches:\n                    # Forward pass for this stage and microbatch\n                    if stage == 0:\n                        # First stage takes input from the microbatch\n                        inputs = microbatches[microbatch_idx][0].to(\n                            next(self.partitioned_model[0].parameters()).device\n                        )\n                    else:\n                        # Other stages take input from previous stage\n                        inputs = self.activation_buffers[stage][microbatch_idx]\n\n                    # Process through model partition\n                    outputs = self.partitioned_model[stage](inputs)\n\n                    # Store activation for next stage\n                    if stage &lt; self.num_stages - 1:\n                        self.activation_buffers[stage + 1][microbatch_idx] = outputs\n                    else:\n                        # For last stage, compute loss and backward\n                        targets = microbatches[microbatch_idx][1].to(outputs.device)\n                        loss = loss_fn(outputs, targets) / self.num_microbatches\n                        loss.backward()\n\n        # Apply accumulated gradients\n        for opt in self.optimizers:\n            opt.step()\n</code></pre>"},{"location":"components/scalability/#sharded-dataset-management","title":"Sharded Dataset Management","text":"<p>For handling datasets too large to fit in memory:</p> <pre><code>class ShardedDatasetManager:\n    def __init__(self, data_root, shard_size_mb=1024, cache_size_mb=4096):\n        self.data_root = data_root\n        self.shard_size_mb = shard_size_mb\n        self.cache = LRUCache(max_size_mb=cache_size_mb)\n        self.shard_index = self._build_shard_index()\n\n    def _build_shard_index(self):\n        \"\"\"Build an index of all data shards.\"\"\"\n        index = {}\n        for shard_path in glob.glob(os.path.join(self.data_root, \"shard_*.index\")):\n            shard_id = int(os.path.basename(shard_path).split(\"_\")[1].split(\".\")[0])\n            with open(shard_path, 'r') as f:\n                shard_contents = json.load(f)\n                for item_id, offset in shard_contents.items():\n                    index[item_id] = (shard_id, offset)\n        return index\n\n    def get_item(self, item_id):\n        \"\"\"Retrieve an item by ID, handling shard loading as needed.\"\"\"\n        # Check if item is in cache\n        if item_id in self.cache:\n            return self.cache[item_id]\n\n        # Look up shard and offset\n        if item_id not in self.shard_index:\n            raise KeyError(f\"Item {item_id} not found in dataset\")\n\n        shard_id, offset = self.shard_index[item_id]\n\n        # Load shard if not in memory\n        shard_path = os.path.join(self.data_root, f\"shard_{shard_id}.data\")\n        with open(shard_path, 'rb') as f:\n            f.seek(offset)\n            # Read item header to get size\n            item_size = struct.unpack(\"Q\", f.read(8))[0]\n            # Read item data\n            item_data = f.read(item_size)\n\n        # Deserialize item\n        item = pickle.loads(item_data)\n\n        # Cache for future use\n        self.cache[item_id] = item\n\n        return item\n\n    def get_batch(self, item_ids):\n        \"\"\"Efficiently retrieve a batch of items, minimizing shard loads.\"\"\"\n        # Group by shard to reduce shard loading\n        items_by_shard = defaultdict(list)\n        for item_id in item_ids:\n            if item_id in self.shard_index:\n                shard_id, _ = self.shard_index[item_id]\n                items_by_shard[shard_id].append(item_id)\n\n        # Load items, one shard at a time\n        batch = []\n        for shard_id, shard_item_ids in items_by_shard.items():\n            for item_id in shard_item_ids:\n                batch.append(self.get_item(item_id))\n\n        return batch\n</code></pre>"},{"location":"components/scalability/#efficient-circuit-analysis","title":"Efficient Circuit Analysis","text":"<p>Scaling our circuit extraction and analysis pipeline:</p>"},{"location":"components/scalability/#distributed-activation-collection","title":"Distributed Activation Collection","text":"<pre><code>class DistributedActivationCollector:\n    def __init__(self, model, layer_names, world_size, rank):\n        self.model = model\n        self.layer_names = layer_names\n        self.world_size = world_size\n        self.rank = rank\n        self.hooks = self._register_hooks()\n        self.activations = {name: [] for name in layer_names}\n\n    def _register_hooks(self):\n        \"\"\"Register forward hooks to collect activations.\"\"\"\n        hooks = []\n        for name, layer in self._get_named_layers():\n            if name in self.layer_names:\n                hook = layer.register_forward_hook(\n                    lambda mod, inp, out, name=name: self._save_activation(name, out)\n                )\n                hooks.append(hook)\n        return hooks\n\n    def _save_activation(self, name, activation):\n        \"\"\"Save activation from a layer.\"\"\"\n        # Clone and detach to avoid memory leaks\n        self.activations[name].append(activation.clone().detach().cpu())\n\n    def collect_activations(self, dataloader, batch_limit=None):\n        \"\"\"Collect activations from the dataloader.\"\"\"\n        # Clear previous activations\n        for name in self.layer_names:\n            self.activations[name] = []\n\n        self.model.eval()\n        with torch.no_grad():\n            for batch_idx, (inputs, _) in enumerate(dataloader):\n                if batch_limit and batch_idx &gt;= batch_limit:\n                    break\n\n                # Only process examples assigned to this rank\n                if batch_idx % self.world_size == self.rank:\n                    self.model(inputs.to(self._get_device()))\n\n        # Gather activations from all processes\n        all_activations = self._gather_activations()\n\n        return all_activations\n\n    def _gather_activations(self):\n        \"\"\"Gather activations from all processes.\"\"\"\n        all_activations = {name: [] for name in self.layer_names}\n\n        for name in self.layer_names:\n            # Convert local activations to tensor\n            local_acts = torch.cat(self.activations[name], dim=0)\n\n            # All-gather to collect from all processes\n            gathered_acts = [torch.zeros_like(local_acts) for _ in range(self.world_size)]\n            torch.distributed.all_gather(gathered_acts, local_acts)\n\n            # Concatenate results\n            all_activations[name] = torch.cat(gathered_acts, dim=0)\n\n        return all_activations\n</code></pre>"},{"location":"components/scalability/#parallel-dictionary-learning","title":"Parallel Dictionary Learning","text":"<pre><code>class ParallelDictionaryLearner:\n    def __init__(self, n_components, sparsity_constraint, world_size, rank):\n        self.n_components = n_components\n        self.sparsity_constraint = sparsity_constraint\n        self.world_size = world_size\n        self.rank = rank\n        self.dictionary = None\n\n    def fit(self, data, n_iterations=100):\n        \"\"\"Fit dictionary learning model in parallel.\"\"\"\n        # Split data according to rank\n        local_data = self._split_data(data)\n\n        # Initialize dictionary (same on all ranks)\n        dictionary_shape = (self.n_components, local_data.shape[1])\n        np.random.seed(42)  # Ensure same initialization across ranks\n        self.dictionary = np.random.randn(*dictionary_shape)\n        self.dictionary /= np.linalg.norm(self.dictionary, axis=1, keepdims=True)\n\n        for iteration in range(n_iterations):\n            # 1. Sparse coding step - compute local coefficients\n            local_coeffs = self._sparse_encode(local_data)\n\n            # 2. All-reduce to get global coefficients and sufficient statistics\n            gram_matrix = local_coeffs.T @ local_coeffs\n            covar_matrix = local_data.T @ local_coeffs\n\n            # All-reduce statistics\n            global_gram = np.zeros_like(gram_matrix)\n            global_covar = np.zeros_like(covar_matrix)\n\n            # MPI all-reduce (simplified here)\n            # torch.distributed.all_reduce(torch.tensor(gram_matrix), op=torch.distributed.ReduceOp.SUM)\n            # torch.distributed.all_reduce(torch.tensor(covar_matrix), op=torch.distributed.ReduceOp.SUM)\n\n            # 3. Dictionary update step (same on all processes)\n            for k in range(self.n_components):\n                if global_gram[k, k] &gt; 0:\n                    # Update dictionary element\n                    self.dictionary[k] = global_covar[:, k] / global_gram[k, k]\n                    # Normalize\n                    self.dictionary[k] /= max(np.linalg.norm(self.dictionary[k]), 1e-10)\n\n        return self.dictionary\n\n    def _split_data(self, data):\n        \"\"\"Split data according to rank.\"\"\"\n        n_samples = data.shape[0]\n        samples_per_rank = n_samples // self.world_size\n        start_idx = self.rank * samples_per_rank\n        end_idx = start_idx + samples_per_rank if self.rank &lt; self.world_size - 1 else n_samples\n        return data[start_idx:end_idx]\n\n    def _sparse_encode(self, data):\n        \"\"\"Compute sparse codes for data using current dictionary.\"\"\"\n        # Implement sparse coding algorithm (e.g., LASSO or OMP)\n        # Returns coefficients matrix of shape (n_samples, n_components)\n        # Simplified implementation:\n        coeffs = np.zeros((data.shape[0], self.n_components))\n        for i in range(data.shape[0]):\n            coeffs[i] = self._encode_sample(data[i])\n        return coeffs\n\n    def _encode_sample(self, sample):\n        \"\"\"Encode a single sample using orthogonal matching pursuit.\"\"\"\n        # Simplified OMP implementation\n        residual = sample.copy()\n        coeffs = np.zeros(self.n_components)\n        selected_indices = []\n\n        for _ in range(self.sparsity_constraint):\n            # Compute correlations with dictionary elements\n            correlations = np.abs(self.dictionary @ residual)\n\n            # Select most correlated element not yet selected\n            valid_indices = [i for i in range(self.n_components) if i not in selected_indices]\n            if not valid_indices:\n                break\n\n            best_idx = valid_indices[np.argmax(correlations[valid_indices])]\n            selected_indices.append(best_idx)\n\n            # Least squares solution for selected dictionary elements\n            D_selected = self.dictionary[selected_indices]\n            coeffs_selected = np.linalg.lstsq(D_selected.T, sample, rcond=None)[0]\n\n            # Update coefficients and residual\n            for j, idx in enumerate(selected_indices):\n                coeffs[idx] = coeffs_selected[j]\n\n            residual = sample - self.dictionary.T @ coeffs\n\n        return coeffs\n</code></pre>"},{"location":"components/scalability/#memory-efficient-circuit-db","title":"Memory-Efficient Circuit DB","text":"<p>For managing large collections of neural circuits:</p> <pre><code>class ScalableCircuitDatabase:\n    def __init__(self, db_path, cache_size=100):\n        self.db_path = db_path\n        self.metadata_db = SqliteDict(f\"{db_path}/metadata.sqlite\", autocommit=True)\n        self.circuit_storage = self._init_storage()\n        self.circuit_cache = LRUCache(max_size=cache_size)\n\n    def _init_storage(self):\n        \"\"\"Initialize the circuit storage backend.\"\"\"\n        storage_path = f\"{self.db_path}/circuits\"\n        os.makedirs(storage_path, exist_ok=True)\n        return storage_path\n\n    def add_circuit(self, circuit_id, circuit, metadata):\n        \"\"\"Add a circuit and its metadata to the database.\"\"\"\n        # Store metadata\n        self.metadata_db[circuit_id] = metadata\n\n        # Serialize and store circuit\n        circuit_path = f\"{self.circuit_storage}/{circuit_id}.pkl\"\n        with open(circuit_path, 'wb') as f:\n            pickle.dump(circuit, f)\n\n        # Add to cache\n        self.circuit_cache[circuit_id] = circuit\n\n    def get_circuit(self, circuit_id):\n        \"\"\"Retrieve a circuit by ID.\"\"\"\n        # Check cache first\n        if circuit_id in self.circuit_cache:\n            return self.circuit_cache[circuit_id]\n\n        # Load from storage\n        circuit_path = f\"{self.circuit_storage}/{circuit_id}.pkl\"\n        if not os.path.exists(circuit_path):\n            raise KeyError(f\"Circuit {circuit_id} not found\")\n\n        with open(circuit_path, 'rb') as f:\n            circuit = pickle.load(f)\n\n        # Add to cache\n        self.circuit_cache[circuit_id] = circuit\n\n        return circuit\n\n    def search_circuits(self, query_dict, limit=10):\n        \"\"\"Search circuits by metadata.\"\"\"\n        results = []\n\n        for circuit_id, metadata in self.metadata_db.items():\n            match = True\n            for key, value in query_dict.items():\n                if key not in metadata or metadata[key] != value:\n                    match = False\n                    break\n\n            if match:\n                results.append((circuit_id, metadata))\n                if len(results) &gt;= limit:\n                    break\n\n        return results\n\n    def get_similar_circuits(self, circuit_id, metric=\"embedding\", k=5):\n        \"\"\"Find circuits similar to the given one.\"\"\"\n        if circuit_id not in self.metadata_db:\n            raise KeyError(f\"Circuit {circuit_id} not found\")\n\n        # Get source circuit's metadata\n        source_metadata = self.metadata_db[circuit_id]\n\n        if metric == \"embedding\" and \"embedding\" in source_metadata:\n            source_embedding = np.array(source_metadata[\"embedding\"])\n\n            # Compute similarity to all circuits\n            similarities = []\n            for cid, metadata in self.metadata_db.items():\n                if cid != circuit_id and \"embedding\" in metadata:\n                    target_embedding = np.array(metadata[\"embedding\"])\n                    similarity = cosine_similarity(source_embedding, target_embedding)\n                    similarities.append((cid, similarity, metadata))\n\n            # Return top-k similar circuits\n            similarities.sort(key=lambda x: x[1], reverse=True)\n            return similarities[:k]\n\n        else:\n            # Fallback to tag-based similarity\n            if \"tags\" not in source_metadata:\n                return []\n\n            source_tags = set(source_metadata[\"tags\"])\n            similarities = []\n\n            for cid, metadata in self.metadata_db.items():\n                if cid != circuit_id and \"tags\" in metadata:\n                    target_tags = set(metadata[\"tags\"])\n                    similarity = len(source_tags.intersection(target_tags)) / len(source_tags.union(target_tags))\n                    similarities.append((cid, similarity, metadata))\n\n            similarities.sort(key=lambda x: x[1], reverse=True)\n            return similarities[:k]\n</code></pre>"},{"location":"components/scalability/#scalable-inference-engine","title":"Scalable Inference Engine","text":"<p>For running composed circuits at scale:</p> <pre><code>class ScalableInferenceEngine:\n    def __init__(self, circuit_db, max_concurrent=8):\n        self.circuit_db = circuit_db\n        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)\n\n    def run_circuit(self, circuit_id, inputs, batch_size=32):\n        \"\"\"Run inference on a circuit in batches.\"\"\"\n        circuit = self.circuit_db.get_circuit(circuit_id)\n\n        # Process in batches\n        all_results = []\n        for i in range(0, len(inputs), batch_size):\n            batch = inputs[i:i+batch_size]\n            batch_results = circuit(batch)\n            all_results.append(batch_results)\n\n        return torch.cat(all_results, dim=0)\n\n    def run_multiple_circuits(self, circuit_ids, inputs):\n        \"\"\"Run multiple circuits in parallel.\"\"\"\n        future_to_circuit = {\n            self.executor.submit(self.run_circuit, cid, inputs): cid\n            for cid in circuit_ids\n        }\n\n        results = {}\n        for future in as_completed(future_to_circuit):\n            circuit_id = future_to_circuit[future]\n            try:\n                results[circuit_id] = future.result()\n            except Exception as e:\n                results[circuit_id] = e\n\n        return results\n\n    def run_composed_circuit(self, composition_plan, inputs):\n        \"\"\"Run a composed circuit by executing subcircuits efficiently.\"\"\"\n        # Extract circuit references and connections\n        circuit_refs = composition_plan.get_circuit_references()\n        connections = composition_plan.get_connections()\n\n        # Topologically sort circuits to determine execution order\n        execution_order = self._topological_sort(circuit_refs, connections)\n\n        # Execute in order, caching intermediate results\n        intermediate_results = {}\n        for circuit_ref in execution_order:\n            circuit_inputs = self._get_circuit_inputs(circuit_ref, connections, intermediate_results, inputs)\n            circuit_outputs = self.run_circuit(circuit_ref.id, circuit_inputs)\n            intermediate_results[circuit_ref.id] = circuit_outputs\n\n        # Return final outputs\n        return self._get_final_outputs(composition_plan, intermediate_results)\n</code></pre>"},{"location":"components/scalability/#resource-monitoring-and-auto-scaling","title":"Resource Monitoring and Auto-Scaling","text":"<p>For dynamically adapting to workload requirements:</p> <pre><code>class ResourceMonitor:\n    def __init__(self, target_utilization=0.8, check_interval=60, min_workers=1, max_workers=16):\n        self.target_utilization = target_utilization\n        self.check_interval = check_interval\n        self.min_workers = min_workers\n        self.max_workers = max_workers\n        self.current_workers = min_workers\n        self.running = False\n        self.monitor_thread = None\n\n    def start(self):\n        \"\"\"Start the resource monitoring thread.\"\"\"\n        if self.running:\n            return\n\n        self.running = True\n        self.monitor_thread = threading.Thread(target=self._monitor_loop)\n        self.monitor_thread.daemon = True\n        self.monitor_thread.start()\n\n    def stop(self):\n        \"\"\"Stop the resource monitoring thread.\"\"\"\n        self.running = False\n        if self.monitor_thread:\n            self.monitor_thread.join()\n\n    def _monitor_loop(self):\n        \"\"\"Main monitoring loop.\"\"\"\n        while self.running:\n            # Check resource utilization\n            cpu_util = psutil.cpu_percent(interval=1) / 100.0\n            mem_util = psutil.virtual_memory().percent / 100.0\n            gpu_util = self._get_gpu_utilization() if torch.cuda.is_available() else 0\n\n            # Determine overall utilization\n            utilization = max(cpu_util, mem_util, gpu_util)\n\n            # Adjust worker count based on utilization\n            if utilization &gt; self.target_utilization * 1.1:\n                # Increase workers if significantly over target\n                new_workers = min(self.current_workers + 1, self.max_workers)\n                if new_workers &gt; self.current_workers:\n                    self.current_workers = new_workers\n                    self._scale_workers(self.current_workers)\n\n            elif utilization &lt; self.target_utilization * 0.7:\n                # Decrease workers if significantly under target\n                new_workers = max(self.current_workers - 1, self.min_workers)\n                if new_workers &lt; self.current_workers:\n                    self.current_workers = new_workers\n                    self._scale_workers(self.current_workers)\n\n            # Sleep before next check\n            time.sleep(self.check_interval)\n\n    def _get_gpu_utilization(self):\n        \"\"\"Get average GPU utilization across all devices.\"\"\"\n        try:\n            return sum(torch.cuda.utilization(i) for i in range(torch.cuda.device_count())) / torch.cuda.device_count() / 100.0\n        except:\n            return 0.0\n\n    def _scale_workers(self, new_count):\n        \"\"\"Scale worker processes to the new count.\"\"\"\n        # Implementation depends on the worker management system\n        # Could call Kubernetes API, Docker Swarm, or other orchestration\n        logging.info(f\"Scaling workers to {new_count}\")\n</code></pre>"},{"location":"components/scalability/#implementation-status","title":"Implementation Status","text":"<p>Current status of our scalability infrastructure:</p> <ul> <li>Distributed Training: Implemented (v0.9)</li> <li>Model Parallelism: Implemented (v0.7)</li> <li>Pipeline Parallelism: Prototype (v0.5)</li> <li>Sharded Dataset: Implemented (v0.8)</li> <li>Distributed Activation Collection: Implemented (v0.8)</li> <li>Parallel Dictionary Learning: Prototype (v0.6)</li> <li>Scalable Circuit DB: Implemented (v0.7)</li> <li>Scalable Inference: Prototype (v0.5)</li> <li>Auto-scaling: Design phase (v0.2)</li> </ul>"},{"location":"components/scalability/#future-directions","title":"Future Directions","text":"<p>Our roadmap for scalability improvements:</p> <ol> <li>Hybrid Parallelism: Combining data, model, and pipeline parallelism</li> <li>Sparse Activation Tracking: Tracking only significant activations to reduce memory usage</li> <li>Federated Circuit Learning: Distributed circuit extraction across organizations</li> <li>Serverless Circuit Execution: On-demand scaling of circuit inference</li> <li>Dynamic Circuit Specialization: Adapting circuit implementations to hardware capabilities </li> </ol>"},{"location":"components/training_pipeline/","title":"Training Pipeline","text":"<p>Our training pipeline is designed to efficiently train models on diverse algorithmic tasks while capturing valuable information about learning dynamics.</p>"},{"location":"components/training_pipeline/#concurrent-training-framework","title":"Concurrent Training Framework","text":"<p>We implement a robust system for running multiple training experiments in parallel:</p> <ul> <li>Distributed Training: Use orchestration tools (Ray, Kubernetes, SLURM) to schedule and manage concurrent training runs</li> <li>Resource Management: Track GPU/TPU usage and optimize job packing for efficient cluster utilization</li> <li>Experiment Tracking: Monitor and log training progress across multiple experiments</li> </ul> <p>This framework allows us to: - Test many hyperparameter combinations efficiently - Train models on different tasks simultaneously  - Compare learning dynamics across tasks and model configurations</p>"},{"location":"components/training_pipeline/#hyperparameter-optimization-hpo","title":"Hyperparameter Optimization (HPO)","text":"<p>We integrate automated hyperparameter optimization to find optimal training configurations:</p> <ul> <li>HPO Libraries: Utilize tools like Optuna, Ray Tune, or Weights &amp; Biases Sweeps</li> <li>Key Parameters: Optimize learning rate, weight decay, batch size, optimizer betas, scheduler parameters</li> <li>Metrics: Focus on optimizing for rapid generalization (grokking speed) and final validation accuracy</li> </ul> <p>Our HPO approach is tightly integrated with the concurrent training framework to maximize resource efficiency.</p>"},{"location":"components/training_pipeline/#optimization-strategy","title":"Optimization Strategy","text":"<p>Our training approach employs techniques known to aid generalization in algorithmic tasks:</p>"},{"location":"components/training_pipeline/#optimizer-selection","title":"Optimizer Selection","text":"<ul> <li>AdamW: Use AdamW as our primary optimizer for its robustness</li> <li>Controlled Weight Decay: Apply appropriate weight decay to promote generalization</li> <li>Parameter Tuning: Carefully tune optimizer parameters for each task</li> </ul>"},{"location":"components/training_pipeline/#learning-dynamics-techniques","title":"Learning Dynamics Techniques","text":"<ul> <li>Learning Rate Schedules: Implement linear warmup followed by cosine decay</li> <li>Gradient Clipping: Prevent instability during training</li> <li>Gradient Noise Injection: Selectively add noise to aid exploration during optimization</li> </ul> <p>These techniques are particularly important for observing phenomena like grokking (delayed generalization) on algorithmic tasks.</p>"},{"location":"components/training_pipeline/#monitoring-comprehensive-logging","title":"Monitoring &amp; Comprehensive Logging","text":"<p>We implement detailed logging to track and analyze model behavior:</p>"},{"location":"components/training_pipeline/#metrics-tracking","title":"Metrics Tracking","text":"<ul> <li>Basic Metrics: Training/validation loss and accuracy</li> <li>Advanced Metrics: Parameter norms, gradient norms, per-class accuracy</li> <li>Learning Phenomena: Track indicators of overfitting, grokking, and double descent</li> </ul>"},{"location":"components/training_pipeline/#visualization-tools","title":"Visualization Tools","text":"<ul> <li>Learning Curves: Plot training/validation metrics over time</li> <li>Parameter Distribution: Visualize weight distributions during training</li> <li>Activation Patterns: Track neuron activations on key examples</li> </ul>"},{"location":"components/training_pipeline/#integration-with-external-tools","title":"Integration with External Tools","text":"<ul> <li>Weights &amp; Biases/TensorBoard: Use these tools for experiment tracking and visualization</li> <li>Custom Dashboards: Create specialized views for analyzing algorithmic learning</li> </ul>"},{"location":"components/training_pipeline/#implementation","title":"Implementation","text":"<p>Our current implementation uses PyTorch for training models on algorithmic tasks. Below is a simplified example of our training loop:</p> <pre><code>class AlgorithmicTaskTrainer:\n    def __init__(self, model, train_dataset, test_dataset, optimizer=None, \n                 lr_scheduler=None, batch_size=64, max_epochs=10000, \n                 patience=1000, device=\"cuda\", log_interval=100):\n        # Initialize trainer with model, datasets, optimizer, etc.\n        # ...\n\n    def train_epoch(self):\n        \"\"\"Train for one epoch and return average loss and accuracy\"\"\"\n        self.model.train()\n        total_loss = 0.0\n        correct_predictions = 0\n        total_predictions = 0\n\n        for batch_idx, (input_ids, target_ids) in enumerate(self.train_dataloader):\n            # Move data to device\n            input_ids = input_ids.to(self.device)\n            target_ids = target_ids.to(self.device)\n\n            # Forward pass\n            self.optimizer.zero_grad()\n            logits = self.model(input_ids)\n\n            # Compute loss\n            loss = self.criterion(logits.view(-1, logits.size(-1)), target_ids.view(-1))\n\n            # Backward pass\n            loss.backward()\n            self.optimizer.step()\n\n            # Update statistics\n            # ...\n\n        return avg_loss, avg_accuracy\n\n    def train(self):\n        \"\"\"Main training loop with early stopping and checkpointing\"\"\"\n        # Implementation of full training loop\n        # ...\n</code></pre>"},{"location":"components/training_pipeline/#future-directions","title":"Future Directions","text":"<p>Future work on the training pipeline includes:</p> <ol> <li>Full-Scale Distributed Training: Scale to large clusters for more extensive experiments</li> <li>Advanced HPO Techniques: Implement Bayesian and population-based HPO methods</li> <li>Curriculum Learning: Develop progressive training curricula for complex tasks</li> <li>Multi-Task Training: Train models on multiple related tasks simultaneously</li> <li>Learning Dynamics Analysis: More sophisticated analysis of grokking and other phenomena </li> </ol>"},{"location":"components/transformer_architecture/","title":"Optimized Transformer Architecture","text":"<p>Our system employs highly optimized transformer architectures designed for algorithmic tasks, with a focus on efficiency, interpretability, and modularity.</p>"},{"location":"components/transformer_architecture/#base-model","title":"Base Model","text":"<p>The foundation of our system is an efficient, decoder-only transformer architecture:</p> <ul> <li>Small, Efficient Models: Initial experiments focus on models similar to those used in grokking studies (~400K parameters, 2 layers, 128 width)</li> <li>Gradual Scaling: We incrementally scale model size as needed for more complex tasks</li> <li>Decoder-Only Design: Our models use the decoder-only architecture, suitable for sequential algorithmic tasks</li> </ul>"},{"location":"components/transformer_architecture/#performance-optimizations","title":"Performance Optimizations","text":"<p>To maximize efficiency and performance, we integrate several key optimizations:</p>"},{"location":"components/transformer_architecture/#flashattention-integration","title":"FlashAttention Integration","text":"<p>We utilize the FlashAttention algorithm to significantly accelerate attention computation:</p> <ul> <li>IO-Aware Implementation: Optimizes memory access patterns for GPUs</li> <li>Reduced Memory Footprint: Avoids materializing large attention matrices</li> <li>Improved Throughput: Much faster training and inference, especially for longer sequences</li> </ul>"},{"location":"components/transformer_architecture/#advanced-attention-mechanisms","title":"Advanced Attention Mechanisms","text":"<p>We experiment with various attention variants to improve capacity and efficiency:</p> <ul> <li>Multigroup/Multilatent Attention: Processes different aspects of inputs concurrently</li> <li>Potential MoE Attention: Mixture-of-Experts attention layers for specialized processing</li> <li>Attention Optimizations: Various optimizations for speed and parameter efficiency</li> </ul> <p>These advanced attention mechanisms can lead to more modular internal representations, which is beneficial for our circuit extraction goals.</p>"},{"location":"components/transformer_architecture/#efficiency-and-modularity-techniques","title":"Efficiency and Modularity Techniques","text":"<p>Beyond basic architectural choices, we employ several techniques to enhance efficiency and modularity:</p>"},{"location":"components/transformer_architecture/#model-pruning","title":"Model Pruning","text":"<p>We investigate various pruning techniques to identify minimal circuits:</p> <ul> <li>Structured Pruning: Remove entire heads or layers</li> <li>Unstructured Pruning: Remove individual weights (magnitude pruning, iterative pruning)</li> <li>During/Post-Training: Apply pruning during or after training</li> </ul> <p>Pruning offers several benefits: - Identifies and removes redundant parameters (30-50%+ reduction target) - Reveals minimal, essential sub-circuits for tasks - Improves inference efficiency - Potentially simplifies circuit extraction</p>"},{"location":"components/transformer_architecture/#lora-adapters-low-rank-adaptation","title":"LoRA Adapters (Low-Rank Adaptation)","text":"<p>We explore using LoRA to efficiently fine-tune models for specific algorithmic tasks:</p> <ul> <li>Parameter Efficiency: Updates only 0.1-1% of total parameters</li> <li>Modularity: Isolates task-specific knowledge in adapters</li> <li>Extraction Benefits: Potentially facilitates cleaner circuit extraction from the adapters themselves</li> </ul> <p>LoRA adapters allow for rapid task specialization without full model retraining, making them ideal for our modular approach.</p>"},{"location":"components/transformer_architecture/#modular-design-philosophy","title":"Modular Design Philosophy","text":"<p>Our transformer is architected with modularity in mind:</p> <ul> <li>Swappable Components: Attention heads and FFN layers are conceptually interchangeable</li> <li>Clean Interfaces: Well-defined interfaces between components</li> <li>Isolation: Mechanisms to isolate and study specific parts of the network</li> </ul> <p>This modular design philosophy facilitates experimentation and potentially enables more direct forms of circuit swapping in composed systems.</p>"},{"location":"components/transformer_architecture/#implementation","title":"Implementation","text":"<p>Our current implementation uses a simple transformer model with standard attention. Below is a simplified example of our attention mechanism:</p> <pre><code>class MultiHeadAttention(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.num_attention_heads = config.num_attention_heads\n        self.attention_head_size = config.hidden_size // config.num_attention_heads\n        self.all_head_size = self.num_attention_heads * self.attention_head_size\n\n        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n\n        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n        self.out = nn.Linear(config.hidden_size, config.hidden_size)\n\n    def forward(self, hidden_states, attention_mask=None):\n        # Implementation of multi-head attention\n        # ...\n        return attention_output\n</code></pre>"},{"location":"components/transformer_architecture/#future-directions","title":"Future Directions","text":"<p>Future work on the transformer architecture includes:</p> <ol> <li>FlashAttention Integration: Implement and benchmark FlashAttention for improved efficiency</li> <li>Structured Pruning Studies: Systematically study the impact of pruning on circuit extraction</li> <li>LoRA Implementation: Add LoRA adapters for efficient fine-tuning</li> <li>Architecture Search: Explore optimal architectures for specific algorithmic tasks</li> <li>Scaling Laws: Investigate scaling relationships for algorithmic tasks </li> </ol>"}]}